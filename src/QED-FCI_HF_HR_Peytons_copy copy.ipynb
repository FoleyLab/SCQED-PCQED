{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57746595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/883k4s4x7qj7sr5ypdpszg9n7510f8/T/ipykernel_82794/4003142107.py:13: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "import psi4\n",
    "from helper_PFCI import PFHamiltonianGenerator\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants\n",
    "from numpy.polynomial import Polynomial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4f72cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_au:  1744.6310991830007\n"
     ]
    }
   ],
   "source": [
    "#calculate some constants for HH\n",
    "\n",
    "amu_to_au = 1822.89\n",
    "\n",
    "\n",
    "mA_kg = 1.00784 * (10 ** (-3) / (6.022 * 10 ** 23) )\n",
    "mB_kg = 18.998403 * (10 ** (-3) / (6.022 * 10 ** 23) )\n",
    "mA_au = 1.00784 * amu_to_au\n",
    "mB_au = 18.998403 * amu_to_au\n",
    "mu_au = (mA_au * mB_au )/ (mA_au + mB_au)\n",
    "mu_kg = (mA_kg * mB_kg) / (mA_kg + mB_kg)  \n",
    "print(\"mu_au: \", mu_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93e9eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ptolley1/Documents/github/SCQED-PCQED/array_data/HF/fci_HF_0_001_pes.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m array_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/ptolley1/Documents/github/SCQED-PCQED/array_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m cavity_E_array_0_00_T \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(array_data \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/HF/fci_HF_0_00_pes.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m----> 3\u001b[0m cavity_E_array_0_001_T \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/HF/fci_HF_0_001_pes.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      4\u001b[0m cavity_E_array_0_005_T \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(array_data \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/HF/fci_HF_0_005_pes.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      5\u001b[0m cavity_E_array_0_01_T \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(array_data \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/HF/fci_HF_0_01_pes.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/envs/work/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ptolley1/Documents/github/SCQED-PCQED/array_data/HF/fci_HF_0_001_pes.npy'"
     ]
    }
   ],
   "source": [
    "array_data = \"/Users/ptolley1/Documents/github/SCQED-PCQED/array_data\"\n",
    "cavity_E_array_0_00_T = np.load(array_data + \"/HF/fci_HF_0_00_pes.npy\").T\n",
    "#cavity_E_array_0_001_T = np.load(array_data + \"/HF/fci_HF_0_001_pes.npy\").T\n",
    "cavity_E_array_0_005_T = np.load(array_data + \"/HF/fci_HF_0_005_pes.npy\").T\n",
    "cavity_E_array_0_01_T = np.load(array_data + \"/HF/fci_HF_0_01_pes.npy\").T\n",
    "cavity_E_array_0_02_T = np.load(array_data + \"/HF/fci_HF_0_02_pes.npy\").T\n",
    "cavity_E_array_0_03_T = np.load(array_data + \"/HF/fci_HF_0_03_pes.npy\").T\n",
    "cavity_E_array_0_04_T = np.load(array_data + \"/HF/fci_HF_0_04_pes.npy\").T\n",
    "cavity_E_array_0_05_T = np.load(array_data + \"/HF/fci_HF_0_05_pes.npy\").T\n",
    "dipoles_0 = np.load(array_data + \"/HF/fci_HF_0_00_dipoles.npy\")\n",
    "#dipoles_001 = np.load(array_data + \"/HF/fci_HF_0_001_dipoles.npy\")\n",
    "dipoles_005 = np.load(array_data + \"/HF/fci_HF_0_005_dipoles.npy\")\n",
    "dipoles_01 = np.load(array_data + \"/HF/fci_HF_0_01_dipoles.npy\")\n",
    "dipoles_02 = np.load(array_data + \"/HF/fci_HF_0_02_dipoles.npy\")\n",
    "dipoles_03 = np.load(array_data + \"/HF/fci_HF_0_03_dipoles.npy\")\n",
    "dipoles_04 = np.load(array_data + \"/HF/fci_HF_0_04_dipoles.npy\")\n",
    "dipoles_05 = np.load(array_data + \"/HF/fci_HF_0_05_dipoles.npy\")\n",
    "#r_data = np.load(array_data + \"/HF/fci_r_array_HF.npy\")\n",
    "N_R = 5\n",
    "r_data = np.linspace(0.915,0.92,N_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.signal import find_peaks\n",
    "def declutter_E_array(E_array, dipoles,  r_data, discontinuity_threshold_std = 1, energy_diff_threshold_std = 2,  num_to_declutter = 2):\n",
    "\n",
    "\n",
    "    #dipole array orderd as [numroots][numroots][dipole vector][bondlength]\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "\n",
    "    d_reshaped= np.zeros_like(E_array)\n",
    "\n",
    "    def vector_magnitude(vector):\n",
    "        return np.sqrt(vector[0]**2 + vector[1]**2 + vector[2]**2)\n",
    "\n",
    "\n",
    "    for q in range(dipoles.shape[3]):\n",
    "        for i in range(dipoles.shape[0]):\n",
    "            for j in range(dipoles.shape[1]):\n",
    "                if i == j:\n",
    "                    d_reshaped[q][i] = vector_magnitude(dipoles[i,i,:,q])\n",
    "  \n",
    "    dipoles = np.copy(d_reshaped)\n",
    "    new_dipoles = np.zeros_like(dipoles)\n",
    "\n",
    "    # plt.plot(dipoles)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    for q in range(0, 5):\n",
    "        #dipole discontinuities\n",
    "        for i in range(0,num_to_declutter):\n",
    "            previous_intersection = 0\n",
    "            for z in range(0,50):\n",
    "                for j in range(i+1, E_array.shape[1]):\n",
    "                    array1 = E_array[:, i]\n",
    "                    array2 = E_array[:, j]\n",
    "\n",
    "                    dipole_array1 = dipoles[:, i] [previous_intersection:]\n",
    "                    dipole_array2 = dipoles[:, j] [previous_intersection:]\n",
    "\n",
    "\n",
    "                    #Only want array from previous intersection so it doesnt get recrossed\n",
    "                    array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                    array2_from_previous_intersection = array2[previous_intersection:]\n",
    "                    #trying to determine how close two energy surfaces get, if they get very close this some evidence that they crossover\n",
    "                    diff_array1 = np.diff(array1_from_previous_intersection)\n",
    "                    diff_array2 = np.diff(array2_from_previous_intersection)\n",
    "                    std1 = np.std(np.abs(diff_array1))\n",
    "                    mean1 = np.mean(np.abs(diff_array1))\n",
    "                    std2 = np.std(np.abs(diff_array2))\n",
    "                    mean2 = np.mean(np.abs(diff_array2))\n",
    "                    energy_diff_threshold = ((mean1 + mean2)/2) + (((std1+std2)/2) * energy_diff_threshold_std)\n",
    "                    #find closest points\n",
    "                    #print(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])))\n",
    "                    closest_indices =np.where(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])) < energy_diff_threshold)\n",
    "                    try:\n",
    "\n",
    "                        #if energies are close and there are two matcjhing discontinuities in dipole arrary \n",
    "                        dipoles_diff_1 = np.diff(dipole_array1)\n",
    "                        dipoles_diff_2 = np.diff(dipole_array2)\n",
    "\n",
    "                        mean_1 = np.mean(dipoles_diff_1)\n",
    "                        mean_2 = np.mean(dipoles_diff_2)\n",
    "\n",
    "                        std_1 = np.std(dipoles_diff_1)\n",
    "                        std_2 = np.std(dipoles_diff_2)\n",
    "                        discontinuity_threshold_pos =  mean_1 + (std_1*discontinuity_threshold_std)\n",
    "                        discontinuity_threshold_neg =  mean_1 - (std_1*discontinuity_threshold_std)\n",
    "                        idx_1 = np.sort(np.concatenate([ np.where( dipoles_diff_1 >  discontinuity_threshold_pos )[0]+1 ,  np.where( dipoles_diff_1 <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "\n",
    "                        discontinuity_threshold_pos =  mean_2 + (std_2*discontinuity_threshold_std)\n",
    "                        discontinuity_threshold_neg =  mean_2 - (std_2*discontinuity_threshold_std)\n",
    "                        idx_2 = np.sort(np.concatenate([ np.where( dipoles_diff_2 >  discontinuity_threshold_pos )[0]+1 ,  np.where( dipoles_diff_2 <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "\n",
    "\n",
    "\n",
    "                        peaks_1 = find_peaks( np.abs(np.diff(dipoles_diff_1)) , prominence= np.mean(np.abs(np.diff(dipoles_diff_1))) )\n",
    "                        peaks_2 = find_peaks( np.abs(np.diff(dipoles_diff_2)) , prominence= np.mean(np.abs(np.diff(dipoles_diff_1))) )\n",
    "\n",
    "\n",
    "                        \n",
    "                        peaks_1 = find_peaks( np.abs(dipoles_diff_1) , prominence= np.mean(np.abs(dipoles_diff_1)) )\n",
    "                        peaks_2 = find_peaks( np.abs(dipoles_diff_2) , prominence= np.mean(np.abs(dipoles_diff_1)) )\n",
    "\n",
    "\n",
    "\n",
    "                        idx_1 = peaks_1[0]+1\n",
    "                        idx_2 = peaks_2[0]+1\n",
    "\n",
    "\n",
    "                        if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "                            mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                            indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                            indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "\n",
    "                            \n",
    "                            if(len(indices_idx1_in_idx2) != 0 ):\n",
    "                                mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                                indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "\n",
    "                                if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "\n",
    "                                    idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "                                    #print(idx)\n",
    "                                    array1_copy = np.array(array1, copy=True)\n",
    "                                    array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                    array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                                    dipole_array1 = dipoles[:, i] \n",
    "                                    dipole_array2 = dipoles[:, j]\n",
    "\n",
    "\n",
    "                                    dipole_array1_copy = np.array(dipole_array1, copy=True)\n",
    "                                    dipole_array1 = np.concatenate([dipole_array1[:idx],  dipole_array2[idx:]])\n",
    "                                    dipole_array2 =np.concatenate([dipole_array2[:idx] , dipole_array1_copy[idx:]])\n",
    "\n",
    "                                    dipoles[:,i] = dipole_array1\n",
    "                                    dipoles[:,j] = dipole_array2\n",
    "                                    E_array[:,i] = array1\n",
    "                                    E_array[:,j] = array2\n",
    "                                    previous_intersection = idx+1\n",
    "                    except():\n",
    "                        print(\"uh oh\")\n",
    "            new_E_array[:,i ] = E_array[:,i]\n",
    "            new_dipoles[:,i ] = dipoles[:, i]\n",
    "\n",
    "\n",
    "            # plt.plot(new_dipoles)\n",
    "            # plt.show()\n",
    "\n",
    "        E_array = np.copy(new_E_array)\n",
    "        new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "                #Only want array from previous intersection so it doesnt get recrossed\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "                #trying to determine how close two energy surfaces get, if they get very close this some evidence that they crossover\n",
    "                diff_array1 = np.diff(array1_from_previous_intersection)\n",
    "                diff_array2 = np.diff(array2_from_previous_intersection)\n",
    "                std1 = np.std(np.abs(diff_array1))\n",
    "                mean1 = np.mean(np.abs(diff_array1))\n",
    "                std2 = np.std(np.abs(diff_array2))\n",
    "                mean2 = np.mean(np.abs(diff_array2))\n",
    "                energy_diff_threshold = ((mean1 + mean2)/2) + (((std1+std2)/2) * energy_diff_threshold_std)\n",
    "                #find closest points\n",
    "                #print(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])))\n",
    "                closest_indices =np.where(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])) < energy_diff_threshold)\n",
    "                try:\n",
    "                    #use discontinuties in second derivative, discontinutities defined using standard deviation\n",
    "                    dy_1 = np.abs(np.gradient(np.gradient(array1_from_previous_intersection, r_data[previous_intersection:], edge_order = 1), r_data[previous_intersection:], edge_order = 1))\n",
    "                    std = np.std(abs(np.diff(dy_1)))\n",
    "                    mean = np.mean(abs(np.diff(dy_1)))\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+2\n",
    "                    dy_2= np.abs(np.gradient(np.gradient(array2_from_previous_intersection, r_data[previous_intersection:], edge_order=1), r_data[previous_intersection:], edge_order=1))\n",
    "                    std = np.std(abs(np.diff(dy_2)))\n",
    "                    mean = np.mean(abs(np.diff(dy_2)))\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+2\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        # indices_idx1_in_idx2  = indices_idx1_in_idx2[ending_index:]\n",
    "                        # starting_index=ending_index\n",
    "                        # ending_index = starting_index\n",
    "                        starting_index = 0\n",
    "                        ending_index = 0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            #print(\"ayo: \", abs((indices_idx1_in_idx2[elem_index]) - (indices_idx1_in_idx2[elem_index+1])))\n",
    "                            if abs((indices_idx1_in_idx2[elem_index]) - (indices_idx1_in_idx2[elem_index+1])) < 25 :\n",
    "                                ending_index = ending_index+1\n",
    "                            else:\n",
    "                                break\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:ending_index]\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "                                for k in range(len(indices_discontinuties_in_energydiff) - 1):\n",
    "                                    idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[k]]+ previous_intersection\n",
    "                                    #print(idx)\n",
    "                                    array1_copy = np.array(array1, copy=True)\n",
    "                                    array1 = np.concatenate([array1[:idx],  array2[idx:idx+1], array1[idx+1:]])\n",
    "                                    array2 = np.concatenate([array2[:idx] , array1_copy[idx:idx+1], array2[idx+1:]])\n",
    "                                    E_array[:,i] = array1\n",
    "                                    E_array[:,j] = array2\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "                                #print(indices_idx1_in_idx2)\n",
    "                                fitting_distance=10\n",
    "                                if abs(indices_idx1_in_idx2[-1] - indices_idx1_in_idx2[0]) < fitting_distance:\n",
    "                                    array1 = array1.tolist()\n",
    "                                    array2 = array2.tolist()\n",
    "                                    r_data_list = r_data.tolist()\n",
    "                                    #fitting region\n",
    "                                    end_discontinuity = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                    start_discontinuity = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "                                    fit_E_data_end = min(end_discontinuity+fitting_distance, len(array1))\n",
    "                                    fit_E_data_start= max(start_discontinuity-fitting_distance, 0)\n",
    "                                    # print(fit_E_data_start)\n",
    "                                    # print(fit_E_data_end)\n",
    "                                    fitting_E_data = array1[fit_E_data_start: start_discontinuity] + array1[end_discontinuity: fit_E_data_end]\n",
    "                                    fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "                                    with warnings.catch_warnings():\n",
    "                                        warnings.simplefilter(\"ignore\")\n",
    "                                        poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "                                    r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "                                    polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "                                    array1 = array1[:fit_E_data_start] + polyvals.tolist() + array1[fit_E_data_end:]\n",
    "                                    fitting_E_data = array2[fit_E_data_start: start_discontinuity] + array2[end_discontinuity: fit_E_data_end]\n",
    "                                    fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "                                    with warnings.catch_warnings():\n",
    "                                        warnings.simplefilter(\"ignore\")\n",
    "                                        poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "                                    r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "                                    polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "                                    array2 = array2[:fit_E_data_start] + polyvals.tolist() + array2[fit_E_data_end:]\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(\"uh oh\")\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return new_E_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebabfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cavity_E_array_0_00  = declutter_E_array(cavity_E_array_0_00_T, dipoles_0, r_data,4, -0.075,num_to_declutter=12)\n",
    "cavity_E_array_0_001  = declutter_E_array(cavity_E_array_0_001_T, dipoles_001, r_data, 4,-0.075,num_to_declutter=12)\n",
    "cavity_E_array_0_005  = declutter_E_array(cavity_E_array_0_005_T , dipoles_005, r_data,4,-0.075,num_to_declutter=12)\n",
    "cavity_E_array_0_01  = declutter_E_array(cavity_E_array_0_01_T, dipoles_01, r_data, 4,-0.075,num_to_declutter=12)\n",
    "cavity_E_array_0_02  = declutter_E_array(cavity_E_array_0_02_T, dipoles_02, r_data,4,-0.075,num_to_declutter=12)\n",
    "cavity_E_array_0_03  = declutter_E_array(cavity_E_array_0_03_T, dipoles_03, r_data,4,-0.075,num_to_declutter=12)\n",
    "cavity_E_array_0_04  = declutter_E_array(cavity_E_array_0_04_T, dipoles_04, r_data,4,0.1,num_to_declutter=12)\n",
    "cavity_E_array_0_05  = declutter_E_array(cavity_E_array_0_05_T, dipoles_05, r_data, 4,-0.075,num_to_declutter=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba3a478",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4dfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cavity_E_array_0_03_T = np.load(array_data + \"/HF/fci_cavity_arrays_HF_6311G0_03.npy\").T\n",
    "\n",
    "# plt.plot(cavity_E_array_0_03_T)\n",
    "# plt.show()\n",
    "\n",
    "# #cavity_E_array_0_03  = declutter_E_array(cavity_E_array_0_03_T, dipoles_03, r_data, 8, 0.1, 1,  0.2,num_to_declutter=12)\n",
    "# cavity_E_array_0_03  = declutter_E_array(cavity_E_array_0_03_T, dipoles_03, r_data, 4, 0.1, 2,  0.1,num_to_declutter=12)\n",
    "\n",
    "# plt.plot(cavity_E_array_0_03)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a144d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( r_data , cavity_E_array_0_00)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_001)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_005)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_01)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_02)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_03)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_04)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c77f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cavity_E_array_0_00[:,7])\n",
    "plt.plot(cavity_E_array_0_05[:,7])\n",
    "plt.plot(cavity_E_array_0_00[:,1])\n",
    "plt.plot(cavity_E_array_0_05[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a48ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LP_0_001 =           cavity_E_array_0_001[:,1]\n",
    "LP_0_005 =            cavity_E_array_0_005[:,1]\n",
    "LP_0_01 =             cavity_E_array_0_01[:,1]\n",
    "LP_0_02 =             cavity_E_array_0_02[:,1]\n",
    "LP_0_03 =             cavity_E_array_0_03[:,1]\n",
    "LP_0_04 =             cavity_E_array_0_04[:,1]\n",
    "LP_0_05 =             cavity_E_array_0_05[:,1]\n",
    "              \n",
    "\n",
    "\n",
    "UP_0_00 =             cavity_E_array_0_00[:,7]\n",
    "UP_0_001 =           cavity_E_array_0_001[:,7]\n",
    "UP_0_005 =            cavity_E_array_0_005[:,7]\n",
    "UP_0_01 =             cavity_E_array_0_01[:,7]\n",
    "UP_0_02 =             cavity_E_array_0_02[:,7]\n",
    "UP_0_03 =             cavity_E_array_0_03[:,7]\n",
    "UP_0_04 =             cavity_E_array_0_04[:,7]\n",
    "UP_0_05 =             cavity_E_array_0_05[:,7]\n",
    "              \n",
    "\n",
    "S0_array = cavity_E_array_0_00[:,0]\n",
    "S1_array = cavity_E_array_0_00[:,7]\n",
    "\n",
    "\n",
    "plt.plot(LP_0_005)\n",
    "plt.plot(LP_0_02)\n",
    "plt.plot(LP_0_03)\n",
    "plt.plot(LP_0_04)\n",
    "plt.plot(LP_0_05)\n",
    "plt.plot(UP_0_005)\n",
    "plt.plot(UP_0_02)\n",
    "plt.plot(UP_0_03)\n",
    "plt.plot(UP_0_04)\n",
    "plt.plot(UP_0_05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66994e19-bf39-4e81-9e46-b6ad75c797f9",
   "metadata": {},
   "source": [
    "First plot the ground-state potential energy surfaces for $ \\text{H2} $ inside and outisde the cavity.  The effect of the cavity will raise the energy slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hbar = 1\n",
    "\n",
    "# number of grid points \n",
    "N = 2001\n",
    "\n",
    "\n",
    "def get_fd_wfn(x, V_y: np.array, use_5_point_stencil = False):\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "\n",
    "    # define grid spacing h\n",
    "    h = x[1]-x[0]\n",
    "\n",
    "    # create arrays for T, V, and H - we truncate the smallest and largest grid points where \n",
    "    # the centered finite difference derivatives cannot be defined\n",
    "    T = np.zeros((N-2, N-2))\n",
    "    V = np.zeros((N-2, N-2))\n",
    "    H = np.zeros((N-2, N-2))\n",
    "\n",
    "    # this uses the 3 point stencil; we can adapt to use a 5 point and it might improve accuracy\n",
    "\n",
    "\n",
    "    if not use_5_point_stencil:\n",
    "        for i in range(N-2):\n",
    "            for j in range(N-2):\n",
    "                if i==j:\n",
    "                    T[i,j]= -2\n",
    "                elif np.abs(i-j)==1:\n",
    "                    T[i,j]=1\n",
    "                else:\n",
    "                    T[i,j]=0\n",
    "\n",
    "        T = -T *( hbar ** 2 / (2 * mu_au* h**2))\n",
    "        #T =  (- (hbar ** 2) / (2* mu_kg)) *  (1 / ( h**2)) * joule_to_hartree  * T\n",
    "\n",
    "\n",
    "    elif use_5_point_stencil:\n",
    "        for i in range(N-2):\n",
    "            for j in range(N-2):\n",
    "                if i==j:\n",
    "                    T[i,j]= -30\n",
    "                elif np.abs(i-j)==1:\n",
    "                    T[i,j]=16\n",
    "                elif np.abs(i-j)==2:\n",
    "                    T[i,j]=-1\n",
    "\n",
    "        T = -T *  ((hbar ** 2) / (2* mu_au))*  (1 / ( 12 * h**2)) \n",
    "\n",
    "\n",
    "    for i in range(N-2):\n",
    "        for j in range(N-2):\n",
    "            if i==j:\n",
    "                V[i,j]= V_y[i+1]\n",
    "            else:\n",
    "                V[i,j]=0\n",
    "                \n",
    "    H = T + V\n",
    "\n",
    "    #print((-T * hbar ** 2 / (2 * mu_kg* h**2)) * (2.294 * 10 ** 17))\n",
    "    #print(V)\n",
    "\n",
    "    vals, vecs = np.linalg.eigh(H)\n",
    "\n",
    "    if np.average(vecs[:, 0]) < 0:\n",
    "        vecs = vecs * -1\n",
    "\n",
    "    return vals, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCF calculator\n",
    "def get_fcf_matrix(potential_1, potential_2, r_data, matrix_size = 6, potential_1_is_groundstate = False):\n",
    "\n",
    "    #geneerate 2 sets of wavefunctions for the potentials\n",
    "\n",
    "    r_data_au = r_data / psi4.constants.bohr2angstroms\n",
    "\n",
    "    min_potential_1_loc = np.argmin(potential_1[:])\n",
    "    r_eq_au =r_data_au[potential_1.argmin()]\n",
    "\n",
    "    print(\"r_eq_au : \" , r_eq_au)\n",
    "\n",
    "\n",
    "    # Fitting S0 PES to a quintic polynomial\n",
    "\n",
    "    poly = np.poly1d(np.polyfit(r_data_au, potential_1, 15))\n",
    "\n",
    "    poly_array = np.asarray(poly)\n",
    "\n",
    "\n",
    "    #Taking first and second derivative of S0 PES and evaluating at r_eq\n",
    "    first_derivative = poly.deriv()\n",
    "    second_derivative = first_derivative.deriv()\n",
    "    k_au = second_derivative(r_eq_au)\n",
    "    print(\"k_au: \", k_au)\n",
    "\n",
    "\n",
    "    angstrom_to_bohr = 1.88973\n",
    "    x_min = r_data_au[0]\n",
    "    x_max = r_data_au[-1]\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "    # number of grid points \n",
    "    N = 2001\n",
    "    # define grid\n",
    "    x = np.linspace(x_min, x_max, N)\n",
    "\n",
    "    V_y = np.polyval(np.asarray(poly), (x))\n",
    "\n",
    "\n",
    "    vals1, vecs1 = get_fd_wfn(x, V_y, use_5_point_stencil=True)\n",
    "    #vals1, vecs1 = get_fd_wfn(x, V_y)\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('bond length (m)')\n",
    "    ax1.set_ylabel('wfn', color=color)\n",
    "    ax1.plot(x[1:N-1], vecs1[:,0], 'r', label = \"$\\psi_0$\")\n",
    "    ax1.plot(x[1:N-1], vecs1[:,1], 'b',label = \"$\\psi_1$\" )\n",
    "    ax1.plot(x[1:N-1], vecs1[:,2], 'g',label = \"$\\psi_2$\")\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('energy (hartree)', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(r_data_au, potential_1, 'bo', label='PES_1')\n",
    "    ax2.plot(r_data_au, poly(r_data_au), 'm-', label='fit')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    min_potential_2_loc = np.argmin(potential_2[:])\n",
    "    r_eq_au =r_data_au[min_potential_2_loc]\n",
    "\n",
    "    print(\"r_eq_au : \" , r_eq_au)\n",
    "\n",
    "\n",
    "    # Fitting S0 PES to a quintic polynomial\n",
    "\n",
    "    #can use this line to only fit to bottom of well for cubic and harmonic\n",
    "    #poly = np.poly1d(np.polyfit(r_data_meters[50:100], fci_S0[50:100], 4))\n",
    "\n",
    "    poly = np.poly1d(np.polyfit(r_data_au, potential_2, 15))\n",
    "\n",
    "    poly_array = np.asarray(poly)\n",
    "\n",
    "\n",
    "    #Taking first and second derivative of S0 PES and evaluating at r_eq\n",
    "    first_derivative = poly.deriv()\n",
    "    second_derivative = first_derivative.deriv()\n",
    "    k_au = second_derivative(r_eq_au)\n",
    "    print(\"k_au: \", k_au)\n",
    "\n",
    "\n",
    "    angstrom_to_bohr = 1.88973\n",
    "    x_min = r_data_au[0]\n",
    "    x_max = r_data_au[-1]\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "    # number of grid points \n",
    "    N = 2001\n",
    "    # define grid\n",
    "    x = np.linspace(x_min, x_max, N)\n",
    "\n",
    "    V_y = np.polyval(np.asarray(poly), (x))\n",
    "\n",
    "\n",
    "    vals2, vecs2 = get_fd_wfn(x, V_y, use_5_point_stencil=True)\n",
    "    #vals2, vecs2 = get_fd_wfn(x, V_y)\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('bond length')\n",
    "    ax1.set_ylabel('wfn', color=color)\n",
    "    ax1.plot(x[1:N-1], vecs2[:,0], 'r',label = \"$\\psi_0$\")\n",
    "    ax1.plot(x[1:N-1], vecs2[:,1], 'b',label = \"$\\psi_1$\")\n",
    "    ax1.plot(x[1:N-1], vecs2[:,2], 'g', label = \"$\\psi_2$\")\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('energy (hartree)', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(r_data_au, potential_2, 'bo', label='PES_2')\n",
    "    ax2.plot(r_data_au, poly(r_data_au), 'm-', label='fit')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    FCF_matrix = np.zeros((matrix_size,matrix_size))\n",
    "\n",
    "    for i in range(FCF_matrix.shape[0]):\n",
    "        for j in range(FCF_matrix.shape[0]):\n",
    "\n",
    "            FCF_matrix[i][j] = np.trapz(vecs1[:,i] * vecs2[:,j]) \n",
    "            FCF = np.absolute(FCF_matrix) ** 2 \n",
    "\n",
    "    return FCF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fcf_0_05 = get_fcf_matrix(S0_array,UP_0_05, r_data, 6)\n",
    "\n",
    "fcf_0_04 = get_fcf_matrix(S0_array,UP_0_04, r_data, 6)\n",
    "\n",
    "fcf_0_03 = get_fcf_matrix(S0_array,UP_0_03, r_data, 6)\n",
    "\n",
    "fcf_0_02 = get_fcf_matrix(S0_array,UP_0_02, r_data, 6)\n",
    "\n",
    "fcf_0_005 = get_fcf_matrix(S0_array,UP_0_005, r_data, 6)\n",
    "\n",
    "# fcf_0_001 = get_fcf_matrix(S0_array,UP_0_001, r_data, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d51008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# min_val, max_val = 0, 15\n",
    "# cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "# x=pd.DataFrame(fcf_0_001)\n",
    "# x=x.style.background_gradient(cmap=cm)\n",
    "# display(x)\n",
    "\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_005)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_02)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_03)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_04)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_05)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fcf_S0_S1 = get_fcf_matrix(S0_array,S1_array, r_data, 11)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_S0_S1)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e52241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from html2image import Html2Image\n",
    "hti = Html2Image()\n",
    "hti.screenshot(x.to_html(), save_as = 'FCF_for_HF_ground_to_1_Delta.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
