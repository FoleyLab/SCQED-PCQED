{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "import psi4\n",
    "from helper_PFCI import PFHamiltonianGenerator\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from scipy import constants\n",
    "from numpy.polynomial import Polynomial\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.abspath(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate some constants for LiH\n",
    "\n",
    "amu_to_au = 1822.89\n",
    "\n",
    "\n",
    "mA_kg = 1.00784 * (10 ** (-3) / (6.022 * 10 ** 23) )\n",
    "mB_kg = 6.9410 * (10 ** (-3) / (6.022 * 10 ** 23) )\n",
    "mA_au = 1.00784 * amu_to_au\n",
    "mB_au = 6.9410 * amu_to_au\n",
    "mu_au = (mA_au * mB_au )/ (mA_au + mB_au)\n",
    "mu_kg = (mA_kg * mB_kg) / (mA_kg + mB_kg)  \n",
    "print(\"mu_au: \", mu_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def declutter_E_array(E_array, delta=0.002, num_to_declutter = 6):\n",
    "\n",
    "\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,200):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "\n",
    "                #find closest points\n",
    "                idx =(np.abs(array1[previous_intersection:] - array2[previous_intersection:])).argmin() + previous_intersection\n",
    "\n",
    "\n",
    "                #assume they crossover if they get really close\n",
    "                if np.abs(array1[idx]- array2[idx]) < delta:\n",
    "                        \n",
    "                    #copy one of the arrays\n",
    "                    array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                    array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                    array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                    E_array[:,i] = array1\n",
    "                    E_array[:,j] = array2\n",
    "\n",
    "                previous_intersection = idx\n",
    "\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "\n",
    "    return new_E_array\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declutter_E_array(E_array, discontinuity_threshold=0.0001, energy_diff_threshold = 0.02,  num_to_declutter = 2):\n",
    "\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "\n",
    "\n",
    "                #find closest points\n",
    "                closest_indices =np.where(np.abs(array1[previous_intersection:] - array2[previous_intersection:]) < energy_diff_threshold)\n",
    "                if np.shape(closest_indices)[1] != 0:\n",
    "                    #print(i)\n",
    "                    #print(closest_indices)\n",
    "                    pass\n",
    "\n",
    "\n",
    "                try:\n",
    "                    dy_1 = np.gradient(array1_from_previous_intersection)\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+1\n",
    "\n",
    "                    dy_2= np.gradient(array2_from_previous_intersection)\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+1\n",
    "\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        #print(indices_idx1_in_idx2)\n",
    "\n",
    "\n",
    "                        starting_index=0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            if indices_idx1_in_idx2[elem_index]+1 == indices_idx1_in_idx2[elem_index+1]:\n",
    "                                starting_index = elem_index+1\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:]\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "\n",
    "\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(i)\n",
    "\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "\n",
    "    return new_E_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declutter_E_array(E_array, r_data, discontinuity_threshold=0.0001, energy_diff_threshold = 0.02,  num_to_declutter = 2):\n",
    "\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "\n",
    "\n",
    "                #find closest points\n",
    "                closest_indices =np.where(np.abs(array1[previous_intersection:] - array2[previous_intersection:]) < energy_diff_threshold)\n",
    "                if np.shape(closest_indices)[1] != 0:\n",
    "                    #print(i)\n",
    "                    #print(closest_indices)\n",
    "                    pass\n",
    "\n",
    "\n",
    "                try:\n",
    "                    dy_1 = np.gradient(np.gradient(array1_from_previous_intersection, r_data[previous_intersection:], edge_order = 2), r_data[previous_intersection:], edge_order = 2)\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+2\n",
    "\n",
    "                    dy_2= np.gradient(np.gradient(array2_from_previous_intersection, r_data[previous_intersection:], edge_order=2), r_data[previous_intersection:], edge_order=2)\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+2\n",
    "\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        #print(indices_idx1_in_idx2)\n",
    "\n",
    "\n",
    "\n",
    "                        starting_index=0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            if indices_idx1_in_idx2[elem_index]+1 == indices_idx1_in_idx2[elem_index+1]:\n",
    "                                starting_index = elem_index+1\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:]\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "\n",
    "\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(i)\n",
    "\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "\n",
    "    return new_E_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declutter_E_array(E_array, r_data, discontinuity_threshold=0.0001, energy_diff_threshold = 0.02,  num_to_declutter = 2):\n",
    "\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "\n",
    "\n",
    "                #find closest points\n",
    "                closest_indices =np.where(np.abs(array1[previous_intersection:] - array2[previous_intersection:]) < energy_diff_threshold)\n",
    "                if np.shape(closest_indices)[1] != 0:\n",
    "                    #print(i)\n",
    "                    #print(closest_indices)\n",
    "                    pass\n",
    "\n",
    "\n",
    "                try:\n",
    "                    dy_1 = np.abs(np.gradient(np.gradient(array1_from_previous_intersection, r_data[previous_intersection:], edge_order = 2), r_data[previous_intersection:], edge_order = 2))\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+2\n",
    "\n",
    "                    dy_2= np.abs(np.gradient(np.gradient(array2_from_previous_intersection, r_data[previous_intersection:], edge_order=2), r_data[previous_intersection:], edge_order=2))\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+2\n",
    "\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        #print(indices_idx1_in_idx2)\n",
    "\n",
    "\n",
    "\n",
    "                        starting_index=0\n",
    "                        ending_index = 0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            if indices_idx1_in_idx2[elem_index]+1 == indices_idx1_in_idx2[elem_index+1]:\n",
    "                                ending_index = elem_index+1\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:ending_index]\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            print(indices_discontinuties_in_energydiff)\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "\n",
    "\n",
    "                                for k in range(len(indices_discontinuties_in_energydiff) - 1):\n",
    "\n",
    "                                    idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[indices_discontinuties_in_energydiff[k]]]+ previous_intersection\n",
    "                                    #print(idx)\n",
    "\n",
    "                                    array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                                    array1 = np.concatenate([array1[:idx],  array2[idx:idx+1], array1[idx+1:]])\n",
    "                                    array2 = np.concatenate([array2[:idx] , array1_copy[idx:idx+1], array2[idx+1:]])\n",
    "\n",
    "\n",
    "                                    E_array[:,i] = array1\n",
    "                                    E_array[:,j] = array2\n",
    "\n",
    "\n",
    "\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "\n",
    "\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(i)\n",
    "\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "\n",
    "    return new_E_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def declutter_E_array(E_array, r_data, discontinuity_threshold_std = 1, energy_diff_threshold_std = 2,  num_to_declutter = 2):\n",
    "\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "\n",
    "                #Only want array from previous intersection so it doesnt get recrossed\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "\n",
    "\n",
    "                #trying to determine how close two energy surfaces get, if they get very close this some evidence that they crossover\n",
    "                diff_array1 = np.diff(array1_from_previous_intersection)\n",
    "                diff_array2 = np.diff(array2_from_previous_intersection)\n",
    "\n",
    "                std1 = np.std(np.abs(diff_array1))\n",
    "                mean1 = np.mean(np.abs(diff_array1))\n",
    "                std2 = np.std(np.abs(diff_array2))\n",
    "                mean2 = np.mean(np.abs(diff_array2))\n",
    "\n",
    "                energy_diff_threshold = ((mean1 + mean2)/2) + (((std1+std2)/2) * energy_diff_threshold_std)\n",
    "\n",
    "                #find closest points\n",
    "                #print(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])))\n",
    "                closest_indices =np.where(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])) < energy_diff_threshold)\n",
    "\n",
    "\n",
    "                try:\n",
    "\n",
    "                    #use discontinuties in second derivative, discontinutities defined using standard deviation\n",
    "                    dy_1 = np.abs(np.gradient(np.gradient(array1_from_previous_intersection, r_data[previous_intersection:], edge_order = 2), r_data[previous_intersection:], edge_order = 2))\n",
    "                    std = np.std(dy_1)\n",
    "                    mean = np.mean(dy_1)\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+2\n",
    "\n",
    "                    dy_2= np.abs(np.gradient(np.gradient(array2_from_previous_intersection, r_data[previous_intersection:], edge_order=2), r_data[previous_intersection:], edge_order=2))\n",
    "                    std = np.std(dy_2)\n",
    "                    mean = np.mean(dy_2)\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+2\n",
    "\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        #print(indices_idx1_in_idx2)\n",
    "\n",
    "\n",
    "\n",
    "                        starting_index=0\n",
    "                        ending_index = 0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            if indices_idx1_in_idx2[elem_index]+1 == indices_idx1_in_idx2[elem_index+1]:\n",
    "                                ending_index = elem_index+1\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:ending_index]\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "\n",
    "\n",
    "                                for k in range(len(indices_discontinuties_in_energydiff) - 1):\n",
    "\n",
    "                                    idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[k]]+ previous_intersection\n",
    "                                    #print(idx)\n",
    "\n",
    "                                    array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                                    array1 = np.concatenate([array1[:idx],  array2[idx:idx+1], array1[idx+1:]])\n",
    "                                    array2 = np.concatenate([array2[:idx] , array1_copy[idx:idx+1], array2[idx+1:]])\n",
    "\n",
    "\n",
    "                                    E_array[:,i] = array1\n",
    "                                    E_array[:,j] = array2\n",
    "\n",
    "\n",
    "\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "\n",
    "\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(\"uh oh\")\n",
    "\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(0, E_array.shape[1]):\n",
    "        #smoothenify uncrossed surfaces\n",
    "        array1 = E_array[:, j]\n",
    "        second_deriv = np.abs(np.gradient(np.gradient(array1, r_data, edge_order = 2), r_data, edge_order = 2))\n",
    "        std = np.std(second_deriv)\n",
    "        mean = np.mean(second_deriv)\n",
    "        discontinuity_threshold =  mean + (std*(discontinuity_threshold_std))\n",
    "        indices = np.where(abs(np.diff(second_deriv)) >  discontinuity_threshold)[0]+2\n",
    "\n",
    "        #store discontinuity regions as lists\n",
    "        discontinuity_regions =[]\n",
    "\n",
    "        discontinuity_region = []\n",
    "        for i in range(len(indices)-1):\n",
    "\n",
    "            if i == 0 & indices[i] +1 == indices[i+1]:\n",
    "                discontinuity_region.append(indices[i])\n",
    "\n",
    "                # if len(indices) == 1:\n",
    "                #     discontinuity_regions.append(discontinuity_region)\n",
    "\n",
    "            elif indices[i]-1 == indices[i-1]:\n",
    "                discontinuity_region.append(indices[i])\n",
    "\n",
    "                if i == len(indices) - 2:\n",
    "                    if indices[i] +1 == indices[i+1]:\n",
    "                        discontinuity_region.append(indices[i+1])\n",
    "                    \n",
    "\n",
    "            elif len(discontinuity_region) != 0 :\n",
    "                discontinuity_regions.append(discontinuity_region)\n",
    "                discontinuity_region = [indices[i]]\n",
    "            else:\n",
    "                discontinuity_region = [indices[i]]\n",
    "\n",
    "        discontinuity_regions.append(discontinuity_region)\n",
    "\n",
    "\n",
    "        for q in range(0,5):\n",
    "            for i in range(len(discontinuity_regions)-2):\n",
    "                if len(discontinuity_regions) > 1 and i < len(discontinuity_regions)-1:\n",
    "                    discontinuity_region = discontinuity_regions[i]\n",
    "                    discontinuity_region_2 = discontinuity_regions[i+1]\n",
    "                    if np.abs(discontinuity_region[-1] - discontinuity_region_2[0]) <= 25:\n",
    "                        new_discontinuity_region = discontinuity_region + discontinuity_region_2 \n",
    "\n",
    "                        discontinuity_regions.pop(i)\n",
    "                        discontinuity_regions.pop(i)\n",
    "                        discontinuity_regions.insert(i, new_discontinuity_region)\n",
    "\n",
    "        array1 = array1.tolist()\n",
    "        r_data_list = r_data.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for discontinuity_region in discontinuity_regions:\n",
    "            if len(discontinuity_region) != 0 :\n",
    "                start_discontinuity =max(discontinuity_region[0]-2,0)\n",
    "                end_discontinuity = min(discontinuity_region[-1]+2,len(array1))\n",
    "\n",
    "                fitting_distance = 20\n",
    "\n",
    "                if max(start_discontinuity-fitting_distance ,0) > 5:\n",
    "\n",
    "                    fit_E_data_start = max(start_discontinuity-fitting_distance ,0) \n",
    "\n",
    "                    fit_E_data_end = min(len(array1), end_discontinuity+fitting_distance )\n",
    "\n",
    "                    fitting_E_data = array1[fit_E_data_start: start_discontinuity] + array1[end_discontinuity: fit_E_data_end]\n",
    "                    fitting_r_data = r_data_list[max(start_discontinuity-fitting_distance ,0): start_discontinuity] + r_data_list[end_discontinuity: min(len(array1), end_discontinuity+fitting_distance )]\n",
    "                \n",
    "\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "\n",
    "                    r_data_fitting_list = r_data_list[max(start_discontinuity-fitting_distance ,0): min(len(array1), end_discontinuity+fitting_distance )]\n",
    "\n",
    "                    polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "\n",
    "\n",
    "                    array1 = array1[:fit_E_data_start] + polyvals.tolist() + array1[fit_E_data_end:]\n",
    "                    \n",
    "\n",
    "                    E_array[:,j] = np.array(array1)\n",
    "\n",
    "            new_E_array[:,j ] = E_array[:,j]\n",
    "\n",
    "\n",
    "\n",
    "    return new_E_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def declutter_E_array(E_array, r_data, discontinuity_threshold_std = 1, energy_diff_threshold_std = 2,  num_to_declutter = 2):\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "                #Only want array from previous intersection so it doesnt get recrossed\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "                #trying to determine how close two energy surfaces get, if they get very close this some evidence that they crossover\n",
    "                diff_array1 = np.diff(array1_from_previous_intersection)\n",
    "                diff_array2 = np.diff(array2_from_previous_intersection)\n",
    "                std1 = np.std(np.abs(diff_array1))\n",
    "                mean1 = np.mean(np.abs(diff_array1))\n",
    "                std2 = np.std(np.abs(diff_array2))\n",
    "                mean2 = np.mean(np.abs(diff_array2))\n",
    "                energy_diff_threshold = ((mean1 + mean2)/2) + (((std1+std2)/2) * energy_diff_threshold_std)\n",
    "                #find closest points\n",
    "                #print(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])))\n",
    "                closest_indices =np.where(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])) < energy_diff_threshold)\n",
    "                try:\n",
    "                    #use discontinuties in second derivative, discontinutities defined using standard deviation\n",
    "                    dy_1 = np.abs(np.gradient(np.gradient(array1_from_previous_intersection, r_data[previous_intersection:], edge_order = 1), r_data[previous_intersection:], edge_order = 1))\n",
    "                    std = np.std(abs(np.diff(dy_1)))\n",
    "                    mean = np.mean(abs(np.diff(dy_1)))\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+2\n",
    "                    dy_2= np.abs(np.gradient(np.gradient(array2_from_previous_intersection, r_data[previous_intersection:], edge_order=1), r_data[previous_intersection:], edge_order=1))\n",
    "                    std = np.std(abs(np.diff(dy_2)))\n",
    "                    mean = np.mean(abs(np.diff(dy_2)))\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+2\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        # indices_idx1_in_idx2  = indices_idx1_in_idx2[ending_index:]\n",
    "                        # starting_index=ending_index\n",
    "                        # ending_index = starting_index\n",
    "                        starting_index = 0\n",
    "                        ending_index = 0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            #print(\"ayo: \", abs((indices_idx1_in_idx2[elem_index]) - (indices_idx1_in_idx2[elem_index+1])))\n",
    "                            if abs((indices_idx1_in_idx2[elem_index]) - (indices_idx1_in_idx2[elem_index+1])) < 25 :\n",
    "                                ending_index = ending_index+1\n",
    "                            else:\n",
    "                                break\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:ending_index]\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "                                for k in range(len(indices_discontinuties_in_energydiff) - 1):\n",
    "                                    idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[k]]+ previous_intersection\n",
    "                                    #print(idx)\n",
    "                                    array1_copy = np.array(array1, copy=True)\n",
    "                                    array1 = np.concatenate([array1[:idx],  array2[idx:idx+1], array1[idx+1:]])\n",
    "                                    array2 = np.concatenate([array2[:idx] , array1_copy[idx:idx+1], array2[idx+1:]])\n",
    "                                    E_array[:,i] = array1\n",
    "                                    E_array[:,j] = array2\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "                                #print(indices_idx1_in_idx2)\n",
    "                                fitting_distance=10\n",
    "                                if abs(indices_idx1_in_idx2[-1] - indices_idx1_in_idx2[0]) < fitting_distance:\n",
    "                                    array1 = array1.tolist()\n",
    "                                    array2 = array2.tolist()\n",
    "                                    r_data_list = r_data.tolist()\n",
    "                                    #fitting region\n",
    "                                    end_discontinuity = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                    start_discontinuity = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "                                    fit_E_data_end = min(end_discontinuity+fitting_distance, len(array1))\n",
    "                                    fit_E_data_start= max(start_discontinuity-fitting_distance, 0)\n",
    "                                    # print(fit_E_data_start)\n",
    "                                    # print(fit_E_data_end)\n",
    "                                    fitting_E_data = array1[fit_E_data_start: start_discontinuity] + array1[end_discontinuity: fit_E_data_end]\n",
    "                                    fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "                                    with warnings.catch_warnings():\n",
    "                                        warnings.simplefilter(\"ignore\")\n",
    "                                        poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "                                    r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "                                    polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "                                    array1 = array1[:fit_E_data_start] + polyvals.tolist() + array1[fit_E_data_end:]\n",
    "                                    fitting_E_data = array2[fit_E_data_start: start_discontinuity] + array2[end_discontinuity: fit_E_data_end]\n",
    "                                    fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "                                    with warnings.catch_warnings():\n",
    "                                        warnings.simplefilter(\"ignore\")\n",
    "                                        poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "                                    r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "                                    polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "                                    array2 = array2[:fit_E_data_start] + polyvals.tolist() + array2[fit_E_data_end:]\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(\"uh oh\")\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "    return new_E_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def declutter_E_array(E_array, dipoles,  r_data, discontinuity_threshold_std = 2, energy_diff_threshold_std = 2,  num_to_declutter = 2):\n",
    "\n",
    "\n",
    "    d_matrices = np.zeros((num_to_declutter , num_to_declutter, r_data.shape[0]) )\n",
    "    diff_d_matrices =  np.zeros((num_to_declutter , num_to_declutter, r_data.shape[0]-1))\n",
    "\n",
    "    def build_dipole_mag_matrix(dipoles, n_elec, r_):\n",
    "\n",
    "        \n",
    "        d_matrix = np.zeros((n_elec,n_elec))\n",
    "\n",
    "        def vector_magnitude(vector):\n",
    "            return np.sqrt(vector[0]**2 + vector[1]**2 + vector[2]**2)\n",
    "\n",
    "\n",
    "        for i in range(n_elec):\n",
    "            for j in range(n_elec):\n",
    "                d_matrix[i][j] = vector_magnitude(dipoles[i,j,:,r_])\n",
    "\n",
    "\n",
    "        #d_matrix = d_matrix + d_matrix.T - np.diag(np.diag(d_matrix))\n",
    "\n",
    "        return d_matrix\n",
    "    \n",
    "    \n",
    "    #find all discontinutiniutiy locations based on continutity of transition dipoles and dipoles\n",
    "    discontinutity_locs = []\n",
    "\n",
    "    for i in range(0, r_data.shape[0] ):\n",
    "        d_matrices[:, : , i] = build_dipole_mag_matrix(dipoles, num_to_declutter, i)\n",
    "\n",
    "    print(d_matrices.shape)\n",
    "\n",
    "    diff_d_matrices = np.diff(d_matrices)\n",
    "\n",
    "    diff_diff_d_matrices = np.diff(diff_d_matrices)\n",
    "\n",
    "    diff_diff_diff_d_matrices = np.diff(diff_diff_d_matrices)\n",
    "\n",
    "\n",
    "    print(diff_d_matrices.shape)\n",
    "\n",
    "\n",
    "    for z in range(0, 1):\n",
    "        previous_intersection = 0 \n",
    "        for i in range(0,num_to_declutter): \n",
    "            for j in range(i, num_to_declutter):\n",
    "                dipoles_diff = diff_d_matrices[i,j, previous_intersection:]\n",
    "\n",
    "                dipoles_diff[dipoles_diff < 10 **-12] = 0\n",
    "\n",
    "\n",
    "                dipoles_diff_diff = diff_diff_d_matrices[i,j, previous_intersection:]\n",
    "\n",
    "                dipoles_diff_diff[dipoles_diff_diff < 10 **-12] = 0\n",
    "\n",
    "\n",
    "\n",
    "                # plt.plot(diff_d_matrices[i,j, previous_intersection:])\n",
    "                # plt.show()\n",
    "\n",
    "                plt.plot(diff_diff_d_matrices[i,j, previous_intersection:])\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "                #set a threshold for value\n",
    "\n",
    "\n",
    "                mean = np.mean(diff_d_matrices[i, j, previous_intersection:])\n",
    "\n",
    "                std = np.std(diff_d_matrices[i, j, previous_intersection:])\n",
    "\n",
    "                discontinuity_threshold_pos =  mean + (std*discontinuity_threshold_std)\n",
    "                discontinuity_threshold_neg =  mean - (std*discontinuity_threshold_std)\n",
    "                idx_1 = np.sort(np.concatenate([ np.where( dipoles_diff >  discontinuity_threshold_pos )[0]+1 ,  np.where( dipoles_diff <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "\n",
    "\n",
    "                #print(idx_1)\n",
    "\n",
    "\n",
    "\n",
    "                mean = np.mean(diff_diff_d_matrices[i,j, previous_intersection:])\n",
    "\n",
    "                std = np.std(diff_diff_d_matrices[i,j, previous_intersection:])\n",
    "\n",
    "                discontinuity_threshold_pos =  mean + (std*discontinuity_threshold_std)\n",
    "                discontinuity_threshold_neg =  mean - (std*discontinuity_threshold_std)\n",
    "                idx_1 = np.sort(np.concatenate([ np.where( diff_diff_d_matrices[i,j, previous_intersection:] >  discontinuity_threshold_pos )[0]+1 ,  np.where( diff_diff_d_matrices[i,j, previous_intersection:] <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "\n",
    "                large_discontinuties = np.where( diff_diff_d_matrices[i,j, previous_intersection:] > 0.1 )[0]\n",
    "\n",
    "                for q in range(0, len(large_discontinuties)):\n",
    "                    print(diff_diff_d_matrices[i,j, large_discontinuties[q]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(idx_1)\n",
    "\n",
    "\n",
    "\n",
    "                # mean = np.mean(diff_diff_diff_d_matrices[i,j, previous_intersection:])\n",
    "\n",
    "                # std = np.std(diff_diff_diff_d_matrices[i,j, previous_intersection:])\n",
    "\n",
    "                # discontinuity_threshold_pos =  mean + (std*discontinuity_threshold_std)\n",
    "                # discontinuity_threshold_neg =  mean - (std*discontinuity_threshold_std)\n",
    "                # idx_1 = np.sort(np.concatenate([ np.where( diff_diff_diff_d_matrices[i,j, previous_intersection:] >  discontinuity_threshold_pos )[0]+1 ,  np.where( diff_diff_diff_d_matrices[i,j, previous_intersection:] <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "\n",
    "\n",
    "                # print(idx_1)\n",
    "\n",
    "                print( \"i is equal to \",i , \" and j is equal to \", j)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #dipole discontinuities\n",
    "    # for i in range(0,num_to_declutter):\n",
    "    #     previous_intersection = 0\n",
    "    #     for z in range(0,50):\n",
    "    #         for j in range(i+1, E_array.shape[1]):\n",
    "    #             array1 = E_array[:, i]\n",
    "    #             array2 = E_array[:, j]\n",
    "\n",
    "    #             dipole_array1 = dipoles[:, i] [previous_intersection:]\n",
    "    #             dipole_array2 = dipoles[:, j] [previous_intersection:]\n",
    "\n",
    "\n",
    "    #             #Only want array from previous intersection so it doesnt get recrossed\n",
    "    #             array1_from_previous_intersection = array1[previous_intersection:]\n",
    "    #             array2_from_previous_intersection = array2[previous_intersection:]\n",
    "    #             #trying to determine how close two energy surfaces get, if they get very close this some evidence that they crossover\n",
    "    #             diff_array1 = np.diff(array1_from_previous_intersection)\n",
    "    #             diff_array2 = np.diff(array2_from_previous_intersection)\n",
    "    #             std1 = np.std(np.abs(diff_array1))\n",
    "    #             mean1 = np.mean(np.abs(diff_array1))\n",
    "    #             std2 = np.std(np.abs(diff_array2))\n",
    "    #             mean2 = np.mean(np.abs(diff_array2))\n",
    "    #             energy_diff_threshold = ((mean1 + mean2)/2) + (((std1+std2)/2) * energy_diff_threshold_std)\n",
    "    #             #find closest points\n",
    "    #             #print(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])))\n",
    "    #             closest_indices =np.where(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])) < energy_diff_threshold)\n",
    "    #             try:\n",
    "\n",
    "    #                 #if energies are close and there are two matcjhing discontinuities in dipole arrary \n",
    "    #                 dipoles_diff_1 = np.diff(dipole_array1)\n",
    "    #                 dipoles_diff_2 = np.diff(dipole_array2)\n",
    "\n",
    "    #                 mean_1 = np.mean(dipoles_diff_1)\n",
    "    #                 mean_2 = np.mean(dipoles_diff_2)\n",
    "\n",
    "    #                 std_1 = np.std(dipoles_diff_1)\n",
    "    #                 std_2 = np.std(dipoles_diff_2)\n",
    "    #                 discontinuity_threshold_pos =  mean_1 + (std_1*discontinuity_threshold_std)\n",
    "    #                 discontinuity_threshold_neg =  mean_1 - (std_1*discontinuity_threshold_std)\n",
    "    #                 idx_1 = np.sort(np.concatenate([ np.where( dipoles_diff_1 >  discontinuity_threshold_pos )[0]+1 ,  np.where( dipoles_diff_1 <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "\n",
    "    #                 discontinuity_threshold_pos =  mean_2 + (std_2*discontinuity_threshold_std)\n",
    "    #                 discontinuity_threshold_neg =  mean_2 - (std_2*discontinuity_threshold_std)\n",
    "    #                 idx_2 = np.sort(np.concatenate([ np.where( dipoles_diff_2 >  discontinuity_threshold_pos )[0]+1 ,  np.where( dipoles_diff_2 <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "\n",
    "\n",
    "\n",
    "    #                 if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "    #                     mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "    #                     indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "    #                     indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "\n",
    "                        \n",
    "    #                     if(len(indices_idx1_in_idx2) != 0 ):\n",
    "    #                         mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "    #                         indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "\n",
    "    #                         if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "\n",
    "    #                             idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "    #                             #print(idx)\n",
    "    #                             array1_copy = np.array(array1, copy=True)\n",
    "    #                             array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "    #                             array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "    #                             dipole_array1 = dipoles[:, i] \n",
    "    #                             dipole_array2 = dipoles[:, j]\n",
    "\n",
    "\n",
    "    #                             dipole_array1_copy = np.array(dipole_array1, copy=True)\n",
    "    #                             dipole_array1 = np.concatenate([dipole_array1[:idx],  dipole_array2[idx:]])\n",
    "    #                             dipole_array2 =np.concatenate([dipole_array2[:idx] , dipole_array1_copy[idx:]])\n",
    "\n",
    "    #                             dipoles[:,i] = dipole_array1\n",
    "    #                             dipoles[:,j] = dipole_array2\n",
    "    #                             E_array[:,i] = array1\n",
    "    #                             E_array[:,j] = array2\n",
    "    #                             previous_intersection = idx+1\n",
    "    #             except():\n",
    "    #                 print(\"uh oh\")\n",
    "    #     new_E_array[:,i ] = E_array[:,i]\n",
    "    #     new_dipoles[:,i ] = dipoles[:, i]\n",
    "\n",
    "    # E_array = np.copy(new_E_array)\n",
    "    # new_E_array = np.zeros_like(E_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipoles_0 = np.load(\"/Users/proden/Code/npy_files/H_0_53_10_photons/dipoles_H2_0.npy\")\n",
    "cavity_E_array_0 = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0.npy\").T\n",
    "r_data = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_r_array_H2_6311g0_05.npy\")\n",
    "\n",
    "declutter_E_array(cavity_E_array_0, dipoles_0, r_data, 12 , 1, num_to_declutter=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cavity_E_array_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5])\n",
    "print(np.diff(x))\n",
    "\n",
    "x = np.array([[[1,2], [3,4]] , [[5,6], [7,8]], [[9,10], [11,12]]])\n",
    "print(x)\n",
    "\n",
    "x = x.transpose()\n",
    "print(x)\n",
    "\n",
    "print(np.diff(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipoles_0 = np.load(\"/Users/proden/Code/npy_files/H_0_53_10_photons/dipoles_H2_0.npy\")\n",
    "r_data = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_r_array_H2_6311g0_05.npy\")\n",
    "\n",
    "print(dipoles_0)\n",
    "cavity_E_array_0 = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0.npy\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dipole_mag_matrix(dipoles, n_elec, r_):\n",
    "\n",
    "    d_matrix = np.zeros((n_elec,n_elec))\n",
    "\n",
    "    def vector_magnitude(vector):\n",
    "        return np.sqrt(vector[0]**2 + vector[1]**2 + vector[2]**2)\n",
    "\n",
    "\n",
    "    for i in range(n_elec):\n",
    "        for j in range(n_elec):\n",
    "            d_matrix[i][j] = vector_magnitude(dipoles[i,j,:,r_])\n",
    "\n",
    "\n",
    "    d_matrix = d_matrix + d_matrix.T - np.diag(np.diag(d_matrix))\n",
    "    return d_matrix\n",
    "\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 0)\n",
    "print(d_matrix[0:4, 0:4])\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 1)\n",
    "print(d_matrix[0:4, 0:4])\n",
    "\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 2)\n",
    "print(d_matrix[0:4, 0:4])\n",
    "\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 3)\n",
    "print(d_matrix[0:4, 0:4])\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 400)\n",
    "print(d_matrix[0:5, 0:5])\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 700)\n",
    "print(d_matrix[0:5, 0:5])\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 1000)\n",
    "print(d_matrix[0:5, 0:5])\n",
    "\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 2000)\n",
    "print(d_matrix[0:12, 0:12])\n",
    "\n",
    "d_matrix = build_dipole_mag_matrix(dipoles_0, 12, 2001)\n",
    "print(d_matrix[0:12, 0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cavity_E_array_0 = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0.npy\").T\n",
    "cavity_E_array_0_05  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0_05.npy\").T\n",
    "cavity_E_array_0_04  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0_04.npy\").T\n",
    "cavity_E_array_0_03  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0_03.npy\").T\n",
    "cavity_E_array_0_01  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0_01.npy\").T\n",
    "cavity_E_array_0_02  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0_02.npy\").T\n",
    "cavity_E_array_0_001  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0_001.npy\").T\n",
    "cavity_E_array_0_005 =np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_cavity_arrays_H2_6311g0_005.npy\").T\n",
    "\n",
    "r_data = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/H2_omega_0_53/om_0_53_fci_r_array_H2_6311g0_05.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cavity_E_array_0)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_05)\n",
    "plt.show()\n",
    "plt.plot(cavity_E_array_0_01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(0, 10):\n",
    "    cavity_free_E_array = declutter_E_array(cavity_E_array_0, r_data, i*0.1, i,num_to_declutter=9)\n",
    "    cavity_E_array_0_05  = declutter_E_array(cavity_E_array_0_05, r_data, i*0.1, i,num_to_declutter=9)\n",
    "    cavity_E_array_0_04  = declutter_E_array(cavity_E_array_0_04,r_data, i*0.1, i,num_to_declutter=9)\n",
    "    cavity_E_array_0_03  = declutter_E_array(cavity_E_array_0_03,r_data,i*0.1, i,num_to_declutter=9)\n",
    "    cavity_E_array_0_02  = declutter_E_array(cavity_E_array_0_02, r_data,  i*0.1, i,num_to_declutter=9)\n",
    "    cavity_E_array_0_01  = declutter_E_array(cavity_E_array_0_01, r_data, i*0.1, i,num_to_declutter=9)\n",
    "    cavity_E_array_0_005  = declutter_E_array(cavity_E_array_0_005 , r_data, i*0.1, i, num_to_declutter=9)\n",
    "    cavity_E_array_0_001  = declutter_E_array(cavity_E_array_0_001 , r_data, i*0.1, i, num_to_declutter=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(r_data, cavity_E_array_0_05 )\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_04 )\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_03 )\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_02 )\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_01 )\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_005 )\n",
    "plt.show()\n",
    "plt.plot(r_data,cavity_free_E_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LP_0_001 = cavity_E_array_0_001[:, 2]\n",
    "UP_0_001 = cavity_E_array_0_001[:, 3]\n",
    "\n",
    "LP_0_005 = cavity_E_array_0_005[:, 2]\n",
    "UP_0_005 = cavity_E_array_0_005[:, 3]\n",
    "LP_0_01 = cavity_E_array_0_01[:, 2]\n",
    "UP_0_01 = cavity_E_array_0_01[:, 3]\n",
    "LP_0_02 = cavity_E_array_0_02[:, 2]\n",
    "UP_0_02 = cavity_E_array_0_02[:, 3]\n",
    "LP_0_03 = cavity_E_array_0_03[:, 2]\n",
    "UP_0_03 = cavity_E_array_0_03[:, 3]\n",
    "LP_0_04 = cavity_E_array_0_04[:, 2]\n",
    "UP_0_04 = cavity_E_array_0_04[:,3]\n",
    "LP_0_05 = cavity_E_array_0_05[:, 2]\n",
    "UP_0_05 = cavity_E_array_0_05[:, 3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fci_S0 = cavity_free_E_array[:,0]\n",
    "fci_S1 = cavity_free_E_array[:,3]\n",
    "plt.plot(r_data, fci_S0 + 0.53, color = 'grey', linestyle = 'dashed')\n",
    "plt.plot(r_data, fci_S1, 'grey', linestyle = 'dashed')\n",
    "plt.plot(r_data, LP_0_05)\n",
    "plt.plot(r_data, UP_0_05)\n",
    "plt.plot(r_data, LP_0_04)\n",
    "plt.plot(r_data, UP_0_04)\n",
    "plt.plot(r_data, LP_0_03)\n",
    "plt.plot(r_data, UP_0_03)\n",
    "plt.plot(r_data, LP_0_02)\n",
    "plt.plot(r_data, UP_0_02)\n",
    "plt.plot(r_data, LP_0_01)\n",
    "plt.plot(r_data, UP_0_01)\n",
    "plt.plot(r_data, LP_0_005)\n",
    "plt.plot(r_data, UP_0_005)\n",
    "plt.plot(r_data, LP_0_001)\n",
    "plt.plot(r_data, UP_0_001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_S0 = cavity_free_E_array[:,0]\n",
    "fci_S1 = cavity_free_E_array[:,3]\n",
    "plt.plot(r_data, fci_S0 + 0.53, color = 'grey', linestyle = 'dashed')\n",
    "plt.plot(r_data, fci_S1, 'grey', linestyle = 'dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(fci_S0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hbar = 1\n",
    "\n",
    "# number of grid points \n",
    "N = 2001\n",
    "\n",
    "\n",
    "def get_fd_wfn(x, V_y: np.array, use_5_point_stencil = False):\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "\n",
    "    # define grid spacing h\n",
    "    h = x[1]-x[0]\n",
    "\n",
    "    # create arrays for T, V, and H - we truncate the smallest and largest grid points where \n",
    "    # the centered finite difference derivatives cannot be defined\n",
    "    T = np.zeros((N-2, N-2))\n",
    "    V = np.zeros((N-2, N-2))\n",
    "    H = np.zeros((N-2, N-2))\n",
    "\n",
    "    # this uses the 3 point stencil; we can adapt to use a 5 point and it might improve accuracy\n",
    "\n",
    "\n",
    "    if not use_5_point_stencil:\n",
    "        for i in range(N-2):\n",
    "            for j in range(N-2):\n",
    "                if i==j:\n",
    "                    T[i,j]= -2\n",
    "                elif np.abs(i-j)==1:\n",
    "                    T[i,j]=1\n",
    "                else:\n",
    "                    T[i,j]=0\n",
    "\n",
    "        T = -T *( hbar ** 2 / (2 * mu_au* h**2))\n",
    "        #T =  (- (hbar ** 2) / (2* mu_kg)) *  (1 / ( h**2)) * joule_to_hartree  * T\n",
    "\n",
    "\n",
    "    elif use_5_point_stencil:\n",
    "        for i in range(N-2):\n",
    "            for j in range(N-2):\n",
    "                if i==j:\n",
    "                    T[i,j]= -30\n",
    "                elif np.abs(i-j)==1:\n",
    "                    T[i,j]=16\n",
    "                elif np.abs(i-j)==2:\n",
    "                    T[i,j]=-1\n",
    "\n",
    "        T = -T *  ((hbar ** 2) / (2* mu_au))*  (1 / ( 12 * h**2)) \n",
    "\n",
    "\n",
    "    for i in range(N-2):\n",
    "        for j in range(N-2):\n",
    "            if i==j:\n",
    "                V[i,j]= V_y[i+1]\n",
    "            else:\n",
    "                V[i,j]=0\n",
    "                \n",
    "    H = T + V\n",
    "\n",
    "    #print((-T * hbar ** 2 / (2 * mu_kg* h**2)) * (2.294 * 10 ** 17))\n",
    "    #print(V)\n",
    "\n",
    "    vals, vecs = np.linalg.eigh(H)\n",
    "\n",
    "    if np.average(vecs[:, 0]) < 0:\n",
    "        vecs = vecs * -1\n",
    "\n",
    "    return vals, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCF calculator\n",
    "def get_fcf_matrix(potential_1, potential_2, r_data, matrix_size = 6, potential_1_is_groundstate = False):\n",
    "\n",
    "    #geneerate 2 sets of wavefunctions for the potentials\n",
    "\n",
    "    r_data_au = r_data / psi4.constants.bohr2angstroms\n",
    "\n",
    "    min_potential_1_loc = np.argmin(potential_1[:])\n",
    "    r_eq_au =r_data_au[potential_1.argmin()]\n",
    "\n",
    "    print(\"r_eq_au : \" , r_eq_au)\n",
    "\n",
    "\n",
    "    # Fitting S0 PES to a quintic polynomial\n",
    "\n",
    "    poly = np.poly1d(np.polyfit(r_data_au, potential_1, 7))\n",
    "\n",
    "    poly_array = np.asarray(poly)\n",
    "\n",
    "\n",
    "    #Taking first and second derivative of S0 PES and evaluating at r_eq\n",
    "    first_derivative = poly.deriv()\n",
    "    second_derivative = first_derivative.deriv()\n",
    "    k_au = second_derivative(r_eq_au)\n",
    "    print(\"k_au: \", k_au)\n",
    "\n",
    "\n",
    "    angstrom_to_bohr = 1.88973\n",
    "    x_min = r_data_au[0]\n",
    "    x_max = r_data_au[-1]\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "    # number of grid points \n",
    "    N = 2001\n",
    "    # define grid\n",
    "    x = np.linspace(x_min, x_max, N)\n",
    "\n",
    "    V_y = np.polyval(np.asarray(poly), (x))\n",
    "\n",
    "\n",
    "    vals1, vecs1 = get_fd_wfn(x, V_y, use_5_point_stencil=True)\n",
    "    #vals1, vecs1 = get_fd_wfn(x, V_y)\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('bond length (m)')\n",
    "    ax1.set_ylabel('wfn', color=color)\n",
    "    ax1.plot(x[1:N-1], vecs1[:,0], 'r', label = \"$\\psi_0$\")\n",
    "    ax1.plot(x[1:N-1], vecs1[:,1], 'b',label = \"$\\psi_1$\" )\n",
    "    ax1.plot(x[1:N-1], vecs1[:,2], 'g',label = \"$\\psi_2$\")\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('energy (hartree)', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(r_data_au, potential_1, 'bo', label='PES_1')\n",
    "    ax2.plot(r_data_au, poly(r_data_au), 'm-', label='fit')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    min_potential_2_loc = np.argmin(potential_2[:])\n",
    "    r_eq_au =r_data_au[min_potential_2_loc]\n",
    "\n",
    "    print(\"r_eq_au : \" , r_eq_au)\n",
    "\n",
    "\n",
    "    # Fitting S0 PES to a quintic polynomial\n",
    "\n",
    "    #can use this line to only fit to bottom of well for cubic and harmonic\n",
    "    #poly = np.poly1d(np.polyfit(r_data_meters[50:100], fci_S0[50:100], 4))\n",
    "\n",
    "    poly = np.poly1d(np.polyfit(r_data_au, potential_2, 7))\n",
    "\n",
    "    poly_array = np.asarray(poly)\n",
    "\n",
    "\n",
    "    #Taking first and second derivative of S0 PES and evaluating at r_eq\n",
    "    first_derivative = poly.deriv()\n",
    "    second_derivative = first_derivative.deriv()\n",
    "    k_au = second_derivative(r_eq_au)\n",
    "    print(\"k_au: \", k_au)\n",
    "\n",
    "\n",
    "    angstrom_to_bohr = 1.88973\n",
    "    x_min = r_data_au[0]\n",
    "    x_max = r_data_au[-1]\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "    # number of grid points \n",
    "    N = 2001\n",
    "    # define grid\n",
    "    x = np.linspace(x_min, x_max, N)\n",
    "\n",
    "    V_y = np.polyval(np.asarray(poly), (x))\n",
    "\n",
    "\n",
    "    vals2, vecs2 = get_fd_wfn(x, V_y, use_5_point_stencil=True)\n",
    "    #vals2, vecs2 = get_fd_wfn(x, V_y)\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('bond length')\n",
    "    ax1.set_ylabel('wfn', color=color)\n",
    "    ax1.plot(x[1:N-1], vecs2[:,0], 'r',label = \"$\\psi_0$\")\n",
    "    ax1.plot(x[1:N-1], vecs2[:,1], 'b',label = \"$\\psi_1$\")\n",
    "    ax1.plot(x[1:N-1], vecs2[:,2], 'g', label = \"$\\psi_2$\")\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('energy (hartree)', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(r_data_au, potential_2, 'bo', label='PES_2')\n",
    "    ax2.plot(r_data_au, poly(r_data_au), 'm-', label='fit')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    FCF_matrix = np.zeros((matrix_size,matrix_size))\n",
    "\n",
    "    for i in range(FCF_matrix.shape[0]):\n",
    "        for j in range(FCF_matrix.shape[0]):\n",
    "\n",
    "            FCF_matrix[i][j] = np.trapz(vecs1[:,i] * vecs2[:,j]) \n",
    "            FCF = np.absolute(FCF_matrix) ** 2 \n",
    "\n",
    "    return FCF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fcf_0_05 = get_fcf_matrix(fci_S0,UP_0_05, r_data, 6)\n",
    "\n",
    "fcf_0_04 = get_fcf_matrix(fci_S0,UP_0_04, r_data, 6)\n",
    "\n",
    "fcf_0_03 = get_fcf_matrix(fci_S0,UP_0_03, r_data, 6)\n",
    "\n",
    "fcf_0_02 = get_fcf_matrix(fci_S0,UP_0_02, r_data, 6)\n",
    "\n",
    "fcf_0_01 = get_fcf_matrix(fci_S0,UP_0_01, r_data, 6)\n",
    "fcf_0_005 = get_fcf_matrix(fci_S0,UP_0_005, r_data, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_005)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_01)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_02)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_03)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_04)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_05)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td_0_005 = np.load(\"/Users/proden/Code/npy_files/LiH_cs_5_photons/cs_5_photons_fci_dipoles_LIH_6311g0_005.npy\")[0,3,:,314]\n",
    "# td_0_01 = np.load(\"/Users/proden/Code/npy_files/LiH_cs_5_photons/cs_5_photons_fci_dipoles_LIH_6311g0_01.npy\")[0,3,:,314]\n",
    "# td_0_02 = np.load(\"/Users/proden/Code/npy_files/LiH_cs_5_photons/cs_5_photons_fci_dipoles_LIH_6311g0_02.npy\")[0,3,:,314]\n",
    "# td_0_03 = np.load(\"/Users/proden/Code/npy_files/LiH_cs_5_photons/cs_5_photons_fci_dipoles_LIH_6311g0_03.npy\")[0,3,:,314]\n",
    "# td_0_04 = np.load(\"/Users/proden/Code/npy_files/LiH_cs_5_photons/cs_5_photons_fci_dipoles_LIH_6311g0_04.npy\")[0,3,:,314]\n",
    "# td_0_05 = np.load(\"/Users/proden/Code/npy_files/LiH_cs_5_photons/cs_5_photons_fci_dipoles_LIH_6311g0_05.npy\")[0,3,:,314]\n",
    "# td_0_1 = np.load(\"/Users/proden/Code/npy_files/LiH_cs_5_photons/cs_5_photons_fci_dipoles_LIH_6311g0_1.npy\")[0,3,:,314]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def vector_magnitude(vector):\n",
    "#     return np.sqrt(vector[0]**2 + vector[1]**2 + vector[2]**2)\n",
    "\n",
    "\n",
    "# td_0_005 = vector_magnitude(td_0_005)**2\n",
    "# td_0_01 = vector_magnitude(td_0_01)**2\n",
    "# td_0_02 = vector_magnitude(td_0_02)**2\n",
    "# td_0_03 = vector_magnitude(td_0_03)**2\n",
    "# td_0_04 = vector_magnitude(td_0_04)**2\n",
    "# td_0_05 = vector_magnitude(td_0_05)**2\n",
    "# td_0_1= vector_magnitude(td_0_1)**2\n",
    "\n",
    "\n",
    "# print(td_0_005)\n",
    "# print(td_0_01)\n",
    "# print(td_0_02)\n",
    "# print(td_0_03)\n",
    "# print(td_0_04)\n",
    "# print(td_0_05)\n",
    "# print(td_0_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_val, max_val = 0, 15\n",
    "# cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "# x=pd.DataFrame(td_0_005*fcf_0_005)\n",
    "# x=x.style.background_gradient(cmap=cm)\n",
    "# display(x)\n",
    "\n",
    "# min_val, max_val = 0, 15\n",
    "# cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "# x=pd.DataFrame(td_0_01*fcf_0_01)\n",
    "# x=x.style.background_gradient(cmap=cm)\n",
    "# display(x)\n",
    "\n",
    "# min_val, max_val = 0, 15\n",
    "# cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "# x=pd.DataFrame(td_0_02*fcf_0_02)\n",
    "# x=x.style.background_gradient(cmap=cm)\n",
    "# display(x)\n",
    "\n",
    "# min_val, max_val = 0, 15\n",
    "# cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "# x=pd.DataFrame(td_0_03 * fcf_0_03)\n",
    "# x=x.style.background_gradient(cmap=cm)\n",
    "# display(x)\n",
    "\n",
    "# min_val, max_val = 0, 15\n",
    "# cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "# x=pd.DataFrame(td_0_04* fcf_0_04)\n",
    "# x=x.style.background_gradient(cmap=cm)\n",
    "# display(x)\n",
    "\n",
    "# min_val, max_val = 0, 15\n",
    "# cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "# x=pd.DataFrame(td_0_05 * fcf_0_05)\n",
    "# x=x.style.background_gradient(cmap=cm)\n",
    "# display(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
