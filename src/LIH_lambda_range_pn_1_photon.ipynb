{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "import psi4\n",
    "from helper_PFCI import PFHamiltonianGenerator\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from scipy import constants\n",
    "from numpy.polynomial import Polynomial\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ptolley1/Documents/GitHub/SCQED-PCQED/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.abspath(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_au:  1604.2437006156372\n"
     ]
    }
   ],
   "source": [
    "#calculate some constants for LiH\n",
    "\n",
    "amu_to_au = 1822.89\n",
    "\n",
    "\n",
    "mA_kg = 1.00784 * (10 ** (-3) / (6.022 * 10 ** 23) )\n",
    "mB_kg = 6.9410 * (10 ** (-3) / (6.022 * 10 ** 23) )\n",
    "mA_au = 1.00784 * amu_to_au\n",
    "mB_au = 6.9410 * amu_to_au\n",
    "mu_au = (mA_au * mB_au )/ (mA_au + mB_au)\n",
    "mu_kg = (mA_kg * mB_kg) / (mA_kg + mB_kg)  \n",
    "print(\"mu_au: \", mu_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef declutter_E_array(E_array, delta=0.002, num_to_declutter = 6):\\n\\n\\n    E_array = np.copy(E_array)\\n    new_E_array = np.zeros_like(E_array)\\n\\n    for i in range(0,num_to_declutter):\\n        previous_intersection = 0\\n        for z in range(0,200):\\n            for j in range(i+1, E_array.shape[1]):\\n                array1 = E_array[:, i]\\n                array2 = E_array[:, j]\\n\\n                #find closest points\\n                idx =(np.abs(array1[previous_intersection:] - array2[previous_intersection:])).argmin() + previous_intersection\\n\\n\\n                #assume they crossover if they get really close\\n                if np.abs(array1[idx]- array2[idx]) < delta:\\n                        \\n                    #copy one of the arrays\\n                    array1_copy = np.array(array1, copy=True)\\n\\n                    array1 = np.concatenate([array1[:idx],  array2[idx:]])\\n                    array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\\n\\n\\n                    E_array[:,i] = array1\\n                    E_array[:,j] = array2\\n\\n                previous_intersection = idx\\n\\n        new_E_array[:,i ] = E_array[:,i]\\n\\n    return new_E_array\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def declutter_E_array(E_array, delta=0.002, num_to_declutter = 6):\n",
    "\n",
    "\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,200):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "\n",
    "                #find closest points\n",
    "                idx =(np.abs(array1[previous_intersection:] - array2[previous_intersection:])).argmin() + previous_intersection\n",
    "\n",
    "\n",
    "                #assume they crossover if they get really close\n",
    "                if np.abs(array1[idx]- array2[idx]) < delta:\n",
    "                        \n",
    "                    #copy one of the arrays\n",
    "                    array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                    array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                    array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                    E_array[:,i] = array1\n",
    "                    E_array[:,j] = array2\n",
    "\n",
    "                previous_intersection = idx\n",
    "\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "\n",
    "    return new_E_array\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declutter_E_array(E_array, discontinuity_threshold=0.0001, energy_diff_threshold = 0.02,  num_to_declutter = 2):\n",
    "\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "\n",
    "\n",
    "                #find closest points\n",
    "                closest_indices =np.where(np.abs(array1[previous_intersection:] - array2[previous_intersection:]) < energy_diff_threshold)\n",
    "                if np.shape(closest_indices)[1] != 0:\n",
    "                    #print(i)\n",
    "                    #print(closest_indices)\n",
    "                    pass\n",
    "\n",
    "\n",
    "                try:\n",
    "                    dy_1 = np.gradient(array1_from_previous_intersection)\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+1\n",
    "\n",
    "                    dy_2= np.gradient(array2_from_previous_intersection)\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+1\n",
    "\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        #print(indices_idx1_in_idx2)\n",
    "\n",
    "\n",
    "                        starting_index=0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            if indices_idx1_in_idx2[elem_index]+1 == indices_idx1_in_idx2[elem_index+1]:\n",
    "                                starting_index = elem_index+1\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:]\n",
    "                        \n",
    "                            \n",
    "                        \n",
    "\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "\n",
    "\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(i)\n",
    "\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "\n",
    "    return new_E_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_cavity_E_array = declutter_E_array(cavity_E_array, 0.00001, 0.002,num_to_declutter=9)\n",
    "# new_cavity_E_array_2 = declutter_E_array(cavity_E_array_2,0.000005, 0.002, num_to_declutter=9)\n",
    "# plt.plot(r_data, new_cavity_E_array)\n",
    "# plt.ylim(-8.1,-7.7)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(r_data, new_cavity_E_array_2)\n",
    "# plt.ylim(-8.1,-7.7)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cavity_free_E_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      2\u001b[0m cavity_E_array_0_05  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_05.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      3\u001b[0m cavity_E_array_0_04  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_04.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/envs/work/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0.npy'"
     ]
    }
   ],
   "source": [
    "\n",
    "cavity_free_E_array = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0.npy\").T\n",
    "cavity_E_array_0_05  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_05.npy\").T\n",
    "cavity_E_array_0_04  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_04.npy\").T\n",
    "cavity_E_array_0_03  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_03.npy\").T\n",
    "cavity_E_array_0_02  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_02.npy\").T\n",
    "cavity_E_array_0_01  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_01.npy\").T\n",
    "cavity_E_array_0_005  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_005.npy\").T\n",
    "cavity_E_array_0_001  = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_cavity_arrays_LIH_6311g0_001.npy\").T\n",
    "r_data = np.load(\"/Users/proden/Code/SCQED-PCQED/array_data/LiH/fci_r_array_LiH.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r_data, cavity_E_array_0_05 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_04 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_03 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_02 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_01 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_005 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data,cavity_free_E_array)\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavity_free_E_array = declutter_E_array(cavity_free_E_array, 0.00001, 0.002,num_to_declutter=9)\n",
    "cavity_E_array_0_05  = declutter_E_array(cavity_E_array_0_05, 0.00001, 0.002,num_to_declutter=9)\n",
    "cavity_E_array_0_04  = declutter_E_array(cavity_E_array_0_04, 0.00001, 0.002,num_to_declutter=9)\n",
    "cavity_E_array_0_03  = declutter_E_array(cavity_E_array_0_03, 0.00001, 0.002,num_to_declutter=9)\n",
    "cavity_E_array_0_02  = declutter_E_array(cavity_E_array_0_02, 0.00001, 0.002,num_to_declutter=9)\n",
    "cavity_E_array_0_01  = declutter_E_array(cavity_E_array_0_01, 0.00001, 0.002,num_to_declutter=9)\n",
    "cavity_E_array_0_005  = declutter_E_array(cavity_E_array_0_005 ,0.000005, 0.002, num_to_declutter=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(r_data, cavity_E_array_0_1 )\n",
    "#plt.ylim(-8.1,-7.7)\n",
    "#plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_05 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_04 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_03 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_02 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_01 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data, cavity_E_array_0_005 )\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()\n",
    "plt.plot(r_data,cavity_free_E_array)\n",
    "plt.ylim(-8.1,-7.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "LP_0_005 = cavity_E_array_0_005[:, 2]\n",
    "UP_0_005 = cavity_E_array_0_005[:, 3]\n",
    "LP_0_01 = cavity_E_array_0_01[:, 2]\n",
    "UP_0_01 = cavity_E_array_0_01[:, 3]\n",
    "LP_0_02 = cavity_E_array_0_02[:, 2]\n",
    "UP_0_02 = cavity_E_array_0_02[:, 3]\n",
    "LP_0_03 = cavity_E_array_0_03[:, 2]\n",
    "UP_0_03 = cavity_E_array_0_03[:, 3]\n",
    "LP_0_04 = cavity_E_array_0_04[:, 2]\n",
    "UP_0_04 = cavity_E_array_0_04[:,3]\n",
    "LP_0_05 = cavity_E_array_0_05[:, 2]\n",
    "UP_0_05 = cavity_E_array_0_05[:, 3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fci_S0 = cavity_free_E_array[:,0]\n",
    "fci_S1 = cavity_free_E_array[:,3]\n",
    "plt.plot(r_data, fci_S0 + 0.12086, color = 'grey', linestyle = 'dashed')\n",
    "plt.plot(r_data, fci_S1, 'grey', linestyle = 'dashed')\n",
    "plt.plot(r_data, LP_0_05)\n",
    "plt.plot(r_data, UP_0_05)\n",
    "plt.plot(r_data, LP_0_04)\n",
    "plt.plot(r_data, UP_0_04)\n",
    "plt.plot(r_data, LP_0_03)\n",
    "plt.plot(r_data, UP_0_03)\n",
    "plt.plot(r_data, LP_0_02)\n",
    "plt.plot(r_data, UP_0_02)\n",
    "plt.plot(r_data, LP_0_01)\n",
    "plt.plot(r_data, UP_0_01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hbar = 1\n",
    "\n",
    "# number of grid points \n",
    "N = 2001\n",
    "\n",
    "\n",
    "def get_fd_wfn(x, V_y: np.array, use_5_point_stencil = False):\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "\n",
    "    # define grid spacing h\n",
    "    h = x[1]-x[0]\n",
    "\n",
    "    # create arrays for T, V, and H - we truncate the smallest and largest grid points where \n",
    "    # the centered finite difference derivatives cannot be defined\n",
    "    T = np.zeros((N-2, N-2))\n",
    "    V = np.zeros((N-2, N-2))\n",
    "    H = np.zeros((N-2, N-2))\n",
    "\n",
    "    # this uses the 3 point stencil; we can adapt to use a 5 point and it might improve accuracy\n",
    "\n",
    "\n",
    "    if not use_5_point_stencil:\n",
    "        for i in range(N-2):\n",
    "            for j in range(N-2):\n",
    "                if i==j:\n",
    "                    T[i,j]= -2\n",
    "                elif np.abs(i-j)==1:\n",
    "                    T[i,j]=1\n",
    "                else:\n",
    "                    T[i,j]=0\n",
    "\n",
    "        T = -T *( hbar ** 2 / (2 * mu_au* h**2))\n",
    "        #T =  (- (hbar ** 2) / (2* mu_kg)) *  (1 / ( h**2)) * joule_to_hartree  * T\n",
    "\n",
    "\n",
    "    elif use_5_point_stencil:\n",
    "        for i in range(N-2):\n",
    "            for j in range(N-2):\n",
    "                if i==j:\n",
    "                    T[i,j]= -30\n",
    "                elif np.abs(i-j)==1:\n",
    "                    T[i,j]=16\n",
    "                elif np.abs(i-j)==2:\n",
    "                    T[i,j]=-1\n",
    "\n",
    "        T = -T *  ((hbar ** 2) / (2* mu_au))*  (1 / ( 12 * h**2)) \n",
    "\n",
    "\n",
    "    for i in range(N-2):\n",
    "        for j in range(N-2):\n",
    "            if i==j:\n",
    "                V[i,j]= V_y[i+1]\n",
    "            else:\n",
    "                V[i,j]=0\n",
    "                \n",
    "    H = T + V\n",
    "\n",
    "    #print((-T * hbar ** 2 / (2 * mu_kg* h**2)) * (2.294 * 10 ** 17))\n",
    "    #print(V)\n",
    "\n",
    "    vals, vecs = np.linalg.eigh(H)\n",
    "\n",
    "    if np.average(vecs[:, 0]) < 0:\n",
    "        vecs = vecs * -1\n",
    "\n",
    "    return vals, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCF calculator\n",
    "def get_fcf_matrix(potential_1, potential_2, r_data, matrix_size = 6, potential_1_is_groundstate = False):\n",
    "\n",
    "    #geneerate 2 sets of wavefunctions for the potentials\n",
    "\n",
    "    r_data_au = r_data / psi4.constants.bohr2angstroms\n",
    "\n",
    "    min_potential_1_loc = np.argmin(potential_1[:])\n",
    "    r_eq_au =r_data_au[potential_1.argmin()]\n",
    "\n",
    "    print(\"r_eq_au : \" , r_eq_au)\n",
    "\n",
    "\n",
    "    # Fitting S0 PES to a quintic polynomial\n",
    "\n",
    "    poly = np.poly1d(np.polyfit(r_data_au, potential_1, 7))\n",
    "\n",
    "    poly_array = np.asarray(poly)\n",
    "\n",
    "\n",
    "    #Taking first and second derivative of S0 PES and evaluating at r_eq\n",
    "    first_derivative = poly.deriv()\n",
    "    second_derivative = first_derivative.deriv()\n",
    "    k_au = second_derivative(r_eq_au)\n",
    "    print(\"k_au: \", k_au)\n",
    "\n",
    "\n",
    "    angstrom_to_bohr = 1.88973\n",
    "    x_min = r_data_au[0]\n",
    "    x_max = r_data_au[-1]\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "    # number of grid points \n",
    "    N = 2001\n",
    "    # define grid\n",
    "    x = np.linspace(x_min, x_max, N)\n",
    "\n",
    "    V_y = np.polyval(np.asarray(poly), (x))\n",
    "\n",
    "\n",
    "    vals1, vecs1 = get_fd_wfn(x, V_y, use_5_point_stencil=True)\n",
    "    #vals1, vecs1 = get_fd_wfn(x, V_y)\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('bond length (m)')\n",
    "    ax1.set_ylabel('wfn', color=color)\n",
    "    ax1.plot(x[1:N-1], vecs1[:,0], 'r', label = \"$\\psi_0$\")\n",
    "    ax1.plot(x[1:N-1], vecs1[:,1], 'b',label = \"$\\psi_1$\" )\n",
    "    ax1.plot(x[1:N-1], vecs1[:,2], 'g',label = \"$\\psi_2$\")\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('energy (hartree)', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(r_data_au, potential_1, 'bo', label='PES_1')\n",
    "    ax2.plot(r_data_au, poly(r_data_au), 'm-', label='fit')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    min_potential_2_loc = np.argmin(potential_2[:])\n",
    "    r_eq_au =r_data_au[min_potential_2_loc]\n",
    "\n",
    "    print(\"r_eq_au : \" , r_eq_au)\n",
    "\n",
    "\n",
    "    # Fitting S0 PES to a quintic polynomial\n",
    "\n",
    "    #can use this line to only fit to bottom of well for cubic and harmonic\n",
    "    #poly = np.poly1d(np.polyfit(r_data_meters[50:100], fci_S0[50:100], 4))\n",
    "\n",
    "    poly = np.poly1d(np.polyfit(r_data_au, potential_2, 7))\n",
    "\n",
    "    poly_array = np.asarray(poly)\n",
    "\n",
    "\n",
    "    #Taking first and second derivative of S0 PES and evaluating at r_eq\n",
    "    first_derivative = poly.deriv()\n",
    "    second_derivative = first_derivative.deriv()\n",
    "    k_au = second_derivative(r_eq_au)\n",
    "    print(\"k_au: \", k_au)\n",
    "\n",
    "\n",
    "    angstrom_to_bohr = 1.88973\n",
    "    x_min = r_data_au[0]\n",
    "    x_max = r_data_au[-1]\n",
    "\n",
    "    hbar = 1\n",
    "\n",
    "    # number of grid points \n",
    "    N = 2001\n",
    "    # define grid\n",
    "    x = np.linspace(x_min, x_max, N)\n",
    "\n",
    "    V_y = np.polyval(np.asarray(poly), (x))\n",
    "\n",
    "\n",
    "    vals2, vecs2 = get_fd_wfn(x, V_y, use_5_point_stencil=True)\n",
    "    #vals2, vecs2 = get_fd_wfn(x, V_y)\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('bond length')\n",
    "    ax1.set_ylabel('wfn', color=color)\n",
    "    ax1.plot(x[1:N-1], vecs2[:,0], 'r',label = \"$\\psi_0$\")\n",
    "    ax1.plot(x[1:N-1], vecs2[:,1], 'b',label = \"$\\psi_1$\")\n",
    "    ax1.plot(x[1:N-1], vecs2[:,2], 'g', label = \"$\\psi_2$\")\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('energy (hartree)', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(r_data_au, potential_2, 'bo', label='PES_2')\n",
    "    ax2.plot(r_data_au, poly(r_data_au), 'm-', label='fit')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    FCF_matrix = np.zeros((matrix_size,matrix_size))\n",
    "\n",
    "    for i in range(FCF_matrix.shape[0]):\n",
    "        for j in range(FCF_matrix.shape[0]):\n",
    "\n",
    "            FCF_matrix[i][j] = np.trapz(vecs1[:,i] * vecs2[:,j]) \n",
    "            FCF = np.absolute(FCF_matrix) ** 2 \n",
    "\n",
    "    return FCF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fcf_0_05 = get_fcf_matrix(fci_S0,UP_0_05, r_data, 6)\n",
    "\n",
    "fcf_0_04 = get_fcf_matrix(fci_S0,UP_0_04, r_data, 6)\n",
    "\n",
    "fcf_0_03 = get_fcf_matrix(fci_S0,UP_0_03, r_data, 6)\n",
    "\n",
    "fcf_0_02 = get_fcf_matrix(fci_S0,UP_0_02, r_data, 6)\n",
    "\n",
    "fcf_0_01 = get_fcf_matrix(fci_S0,UP_0_01, r_data, 6)\n",
    "fcf_0_005 = get_fcf_matrix(fci_S0,UP_0_005, r_data, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_005)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_01)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_02)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_03)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_04)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)\n",
    "\n",
    "min_val, max_val = 0, 15\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "x=pd.DataFrame(fcf_0_05)\n",
    "x=x.style.background_gradient(cmap=cm)\n",
    "display(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
