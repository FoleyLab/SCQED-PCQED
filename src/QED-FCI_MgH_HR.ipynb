{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57746595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "import psi4\n",
    "from helper_PFCI import PFHamiltonianGenerator\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import constants\n",
    "from numpy.polynomial import Polynomial\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a93e9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_data = \"/Users/ptolley1/Documents/Github/SCQED-PCQED/array_data\"\n",
    "cavity_E_array_0_00_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0.npy\").T [20:, :]\n",
    "cavity_E_array_0_001_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0_001.npy\").T [20:, :]\n",
    "cavity_E_array_0_005_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0_005.npy\").T[20:, :]\n",
    "cavity_E_array_0_01_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0_01.npy\").T[20:, :]\n",
    "cavity_E_array_0_02_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0_02.npy\").T[20:, :]\n",
    "cavity_E_array_0_03_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0_03.npy\").T[20:, :]\n",
    "cavity_E_array_0_04_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0_04.npy\").T[20:, :]\n",
    "cavity_E_array_0_05_T = np.load(array_data + \"/MgH/fci_cavity_arrays_MgH_631G0_05.npy\").T[20:, :]\n",
    "dipoles_0 = np.load(array_data + \"/MgH/dipoles_MgH0.npy\")[:,:,:,20:]\n",
    "dipoles_001 = np.load(array_data + \"/MgH/dipoles_MgH0_001.npy\")[:,:,:,20:]\n",
    "dipoles_005 = np.load(array_data + \"/MgH/dipoles_MgH0_005.npy\")[:,:,:,20:]\n",
    "dipoles_01 = np.load(array_data + \"/MgH/dipoles_MgH0_01.npy\")[:,:,:,20:]\n",
    "dipoles_02 = np.load(array_data + \"/MgH/dipoles_MgH0_02.npy\")[:,:,:,20:]\n",
    "dipoles_03 = np.load(array_data + \"/MgH/dipoles_MgH0_03.npy\")[:,:,:,20:]\n",
    "dipoles_04 = np.load(array_data + \"/MgH/dipoles_MgH0_04.npy\")[:,:,:,20:]\n",
    "dipoles_05 = np.load(array_data + \"/MgH/dipoles_MgH0_05.npy\")[:,:,:,20:]\n",
    "r_data = np.load(array_data + \"/MgH/fci_r_array_MgH.npy\")\n",
    "N_R = r_data.shape[0]\n",
    "#N_R = 200\n",
    "r_data = np.linspace(0.5, 3.0, N_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edaef63",
   "metadata": {},
   "source": [
    "## Calculation of k\n",
    "Fit ground state PES of H2 to a quintic polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a682bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def declutter_E_array(E_array, dipoles,  r_data, discontinuity_threshold_std = 2,  energy_diff_threshold_std_p1 = 1,  E_disc_threshold = 3, energy_diff_threshold_std = 2,  num_to_declutter = 2):\n",
    "    \n",
    "    E_array_copy = np.array(E_array, copy = True)\n",
    "\n",
    "    d_matrices = np.zeros((num_to_declutter , num_to_declutter, r_data.shape[0]) )\n",
    "    diff_d_matrices =  np.zeros((num_to_declutter , num_to_declutter, r_data.shape[0]-1))\n",
    "\n",
    "    def build_dipole_mag_matrix(dipoles, n_elec, r_):\n",
    "\n",
    "        \n",
    "        d_matrix = np.zeros((n_elec,n_elec))\n",
    "\n",
    "        def vector_magnitude(vector):\n",
    "            return np.sqrt(vector[0]**2 + vector[1]**2 + vector[2]**2)\n",
    "\n",
    "        for i in range(n_elec):\n",
    "            for j in range(n_elec):\n",
    "                d_matrix[i][j] = vector_magnitude(dipoles[i,j,:,r_])\n",
    "\n",
    "\n",
    "        #d_matrix = d_matrix + d_matrix.T - np.diag(np.diag(d_matrix))\n",
    "\n",
    "        return d_matrix\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0, r_data.shape[0] ):\n",
    "        d_matrices[:, : , i] = build_dipole_mag_matrix(dipoles, num_to_declutter, i)\n",
    "\n",
    "    diff_d_matrices = np.diff(np.diff(d_matrices))\n",
    "    diff_d_matrices[diff_d_matrices < 10**-12] = 0\n",
    "\n",
    "\n",
    "\n",
    "    #store discontinyutity locs as a list of lists like  \n",
    "    # [   [loc, surface_1]  ,     [loc, surface_1] , [loc, surface_1] ]\n",
    "    #find all discontinutiniutiy locations based on continutity of transition dipoles and dipoles\n",
    "    discontinuity_locs = []\n",
    "\n",
    "\n",
    "    for z in range(0, 1):\n",
    "        previous_intersection = 0 \n",
    "        for i in range(0,num_to_declutter): \n",
    "\n",
    "            for j in range(i, num_to_declutter):\n",
    "                dipoles_diff = diff_d_matrices[i,j, previous_intersection:]\n",
    "                mean = np.mean(diff_d_matrices[i, j, previous_intersection:])\n",
    "\n",
    "                std = np.std(diff_d_matrices[i, j, previous_intersection:])\n",
    "\n",
    "                discontinuity_threshold_pos =  mean + (std*discontinuity_threshold_std)\n",
    "                discontinuity_threshold_neg =  mean - (std*discontinuity_threshold_std)\n",
    "                idx_1 = np.sort(np.concatenate([ np.where( dipoles_diff >  discontinuity_threshold_pos )[0]+1 ,  np.where( dipoles_diff <  discontinuity_threshold_neg )[0]+1 ]))\n",
    "                #print(idx_1)\n",
    "\n",
    "                #plt.plot(diff_d_matrices[i, j, previous_intersection:])\n",
    "\n",
    "                if len(idx_1) != 0:\n",
    "                    #getting first point of crossover\n",
    "                    if len(idx_1) > 1:\n",
    "                        idx_1_copy = idx_1.copy()\n",
    "                        while(len(idx_1_copy) > 0 ):\n",
    "                            #print(idx_1_copy)\n",
    "                            crossover_loc = None\n",
    "                            for q in range(len(idx_1_copy) - 1):\n",
    "                                #print(idx_1_copy)\n",
    "                                if idx_1_copy[q] +1 == idx_1_copy[q+1]:\n",
    "                                    #print(\"hello\")\n",
    "                                    idx_1_copy = idx_1_copy[q+1:]\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    crossover_loc = idx_1_copy[q]\n",
    "\n",
    "                                    discontinuity_locs.append([crossover_loc, j])\n",
    "                                    try:\n",
    "                                        idx_1_copy = idx_1_copy[q+1:]\n",
    "                                    except():\n",
    "                                        idx_1_copy = []\n",
    "                                        break\n",
    "\n",
    "                                    break\n",
    "\n",
    "                                if len(idx_1_copy == 1):\n",
    "                                    break\n",
    "\n",
    "                            if len(idx_1_copy) == 1:    \n",
    "                                idx_1_copy = []\n",
    "                                discontinuity_locs.append([idx_1[-1], j])\n",
    "                                break                \n",
    "                        \n",
    "                    elif len(idx_1) == 1:\n",
    "                        discontinuity_locs.append([idx_1[0], j])\n",
    "\n",
    "\n",
    "    #sort and remove repaets\n",
    "    discontinuity_locs  = [list(x) for x in set(tuple(x) for x in discontinuity_locs )]\n",
    "    discontinuity_locs = sorted(discontinuity_locs, key=lambda x: x[0])\n",
    "    #print(discontinuity_locs)\n",
    "\n",
    "    #store discontinity locations like this\n",
    "    # [   [loc, surface_1, surface_2]  ,     [loc, surface_1, surface_2] , [loc, surface_1, surface_2] ]\n",
    "    #find all discontinutiniutiy locations based on continutity of transition dipoles and dipoles\n",
    "\n",
    "    new_discontinuity_locs = []\n",
    "    for q in range(len(discontinuity_locs)):\n",
    "        loc1 = discontinuity_locs[q]\n",
    "        for w in range(len(discontinuity_locs)):\n",
    "            if w != q:\n",
    "                loc2 = discontinuity_locs[w]\n",
    "\n",
    "                if loc1[1] != loc2[1]:\n",
    "\n",
    "                    if loc1[0] == loc2[0]:\n",
    "                        new_discontinuity_locs.append([loc1[0] ,discontinuity_locs[q][1], discontinuity_locs[w][1]])\n",
    "\n",
    "                    if loc1[0] == loc2[0] -1:\n",
    "                        new_discontinuity_locs.append([loc2[0] ,discontinuity_locs[q][1], discontinuity_locs[w][1]])\n",
    "\n",
    "                    if loc1[0] -1 == loc2[0]:\n",
    "                        new_discontinuity_locs.append([loc1[0] ,discontinuity_locs[q][1], discontinuity_locs[w][1]])\n",
    "\n",
    "    #sort and remove repeats again\n",
    "    discontinuity_locs = new_discontinuity_locs\n",
    "    # we need to remove one of these [loc, 1,2] and [loc, 2,1]\n",
    "    for i in range(len(discontinuity_locs)):\n",
    "        if discontinuity_locs[i][1] > discontinuity_locs[i][2]:\n",
    "\n",
    "            copy = discontinuity_locs[i][2] \n",
    "            discontinuity_locs[i][2] = discontinuity_locs[i][1] \n",
    "            discontinuity_locs[i][1] = copy\n",
    "\n",
    "    discontinuity_locs  = [list(x) for x in set(tuple(x) for x in discontinuity_locs )]\n",
    "    discontinuity_locs = sorted(discontinuity_locs, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "    #for every discontinuity loc check and see if energies are very close using standard deviations of differences\n",
    "    #crossover energy arrays\n",
    "    \n",
    "    crossover_points = []\n",
    "    for i in range(len(discontinuity_locs)):\n",
    "        loc = discontinuity_locs[i]\n",
    "\n",
    "        array1 = E_array[:, loc[1]]\n",
    "        array2 = E_array[:, loc[2]]\n",
    "\n",
    "\n",
    "        #trying to determine how close two energy surfaces get, if they get very close this some evidence that they crossover\n",
    "        diff_array1 = np.diff(array1 )\n",
    "        diff_array2 = np.diff(array2 )\n",
    "        std1 = np.std(np.abs(diff_array1))\n",
    "        mean1 = np.mean(np.abs(diff_array1))\n",
    "        std2 = np.std(np.abs(diff_array2))\n",
    "        mean2 = np.mean(np.abs(diff_array2))\n",
    "        energy_diff_threshold = ((mean1 + mean2)/2) + (((std1+std2)/2) * energy_diff_threshold_std_p1)\n",
    "        #find closest points\n",
    "        #print(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])))\n",
    "        closest_indices =np.where(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])) < energy_diff_threshold)[0]\n",
    "        if loc[0] in closest_indices:\n",
    "\n",
    "            crossover_points.append(loc)\n",
    "\n",
    "        \n",
    "    # a few points are like this :[1084, 3, 4] ,[1085, 3, 4], choose the larger one\n",
    "    indices_to_pop = []\n",
    "    for i in range(len(crossover_points)-1):\n",
    "        if crossover_points[i][1] == crossover_points[i+1][1] and crossover_points[i][2] == crossover_points[i+1][2]:\n",
    "            if crossover_points[i][0] +1 == crossover_points[i+1][0]:\n",
    "                indices_to_pop.append(i)\n",
    "    indices_to_pop.sort()\n",
    "    indices_to_pop.reverse()\n",
    "    for i in indices_to_pop:\n",
    "        crossover_points.pop(i)\n",
    "\n",
    "\n",
    "    #perform crossovers:\n",
    "    for i in range(len(crossover_points)):\n",
    "\n",
    "\n",
    "        idx = crossover_points[i][0] + 1\n",
    "\n",
    "        array1 = E_array[:, crossover_points[i][1]]\n",
    "        array2 = E_array[:, crossover_points[i][2]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        array1_copy = np.array(array1, copy=True)\n",
    "        array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "        array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "\n",
    "        fitting_distance = 5\n",
    "        array1 = array1.tolist()\n",
    "        array2 = array2.tolist()\n",
    "        r_data_list = r_data.tolist()\n",
    "        #fitting region\n",
    "        end_discontinuity = crossover_points[i][0]+1\n",
    "        start_discontinuity = crossover_points[i][0] -1\n",
    "        fit_E_data_end = min(end_discontinuity+fitting_distance, len(array1))\n",
    "        fit_E_data_start= max(start_discontinuity-fitting_distance, 0)\n",
    "        # print(fit_E_data_start)\n",
    "        # print(fit_E_data_end)\n",
    "        fitting_E_data = array1[fit_E_data_start: start_discontinuity] + array1[end_discontinuity: fit_E_data_end]\n",
    "        fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "        r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "        polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "        array1 = array1[:fit_E_data_start] + polyvals.tolist() + array1[fit_E_data_end:]\n",
    "        fitting_E_data = array2[fit_E_data_start: start_discontinuity] + array2[end_discontinuity: fit_E_data_end]\n",
    "        fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "        r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "        polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "        array2 = array2[:fit_E_data_start] + polyvals.tolist() + array2[fit_E_data_end:]\n",
    "\n",
    "\n",
    "        E_array[:,crossover_points[i][1]] = array1\n",
    "        E_array[:,crossover_points[i][2]] = array2\n",
    "\n",
    "\n",
    "        #go in and change crossover points to reflect changes in E_array\n",
    "        surface_1 = crossover_points[i][1]\n",
    "        surface_2 = crossover_points[i][2] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for p in range(len(crossover_points)):\n",
    "\n",
    "            if crossover_points[p][1] == surface_1:\n",
    "                crossover_points[p][1] = surface_2\n",
    "\n",
    "            elif crossover_points[p][1] == surface_2:\n",
    "                crossover_points[p][1] = surface_1\n",
    "\n",
    "            if crossover_points[p][2] == surface_1:\n",
    "                crossover_points[p][2] = surface_2\n",
    "\n",
    "            elif crossover_points[p][2] == surface_2:\n",
    "                crossover_points[p][2] = surface_1\n",
    "\n",
    "\n",
    "    discontinuity_threshold_std = E_disc_threshold\n",
    "    \n",
    "    #dipole array orderd as [numroots][numroots][dipole vector][bondlength]\n",
    "    E_array = np.copy(E_array)\n",
    "    new_E_array = np.zeros_like(E_array)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,num_to_declutter):\n",
    "        previous_intersection = 0\n",
    "        for z in range(0,50):\n",
    "            for j in range(i+1, E_array.shape[1]):\n",
    "                array1 = E_array[:, i]\n",
    "                array2 = E_array[:, j]\n",
    "                #Only want array from previous intersection so it doesnt get recrossed\n",
    "                array1_from_previous_intersection = array1[previous_intersection:]\n",
    "                array2_from_previous_intersection = array2[previous_intersection:]\n",
    "                #trying to determine how close two energy surfaces get, if they get very close this some evidence that they crossover\n",
    "                diff_array1 = np.diff(array1_from_previous_intersection)\n",
    "                diff_array2 = np.diff(array2_from_previous_intersection)\n",
    "                std1 = np.std(np.abs(diff_array1))\n",
    "                mean1 = np.mean(np.abs(diff_array1))\n",
    "                std2 = np.std(np.abs(diff_array2))\n",
    "                mean2 = np.mean(np.abs(diff_array2))\n",
    "                energy_diff_threshold = ((mean1 + mean2)/2) + (((std1+std2)/2) * energy_diff_threshold_std)\n",
    "                #find closest points\n",
    "                #print(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])))\n",
    "                closest_indices =np.where(np.abs(np.abs(array1[previous_intersection:]) - np.abs(array2[previous_intersection:])) < energy_diff_threshold)\n",
    "                try:\n",
    "                    #use discontinuties in second derivative, discontinutities defined using standard deviation\n",
    "                    dy_1 = np.abs(np.gradient(np.gradient(array1_from_previous_intersection, r_data[previous_intersection:], edge_order = 1), r_data[previous_intersection:], edge_order = 1))\n",
    "                    std = np.std(abs(np.diff(dy_1)))\n",
    "                    mean = np.mean(abs(np.diff(dy_1)))\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_1 = np.where(abs(np.diff(dy_1)) >  discontinuity_threshold)[0]+2\n",
    "                    dy_2= np.abs(np.gradient(np.gradient(array2_from_previous_intersection, r_data[previous_intersection:], edge_order=1), r_data[previous_intersection:], edge_order=1))\n",
    "                    std = np.std(abs(np.diff(dy_2)))\n",
    "                    mean = np.mean(abs(np.diff(dy_2)))\n",
    "                    discontinuity_threshold =  mean + (std*discontinuity_threshold_std)\n",
    "                    idx_2 = np.where(abs(np.diff(dy_2)) > discontinuity_threshold)[0]+2\n",
    "                    if (len(idx_1)!= 0 and len(idx_2) != 0 ):\n",
    "                        mask_idx1_idx2 = np.isin(idx_1, idx_2)\n",
    "                        indices_idx1_in_idx2 = np.where(mask_idx1_idx2)[0]\n",
    "                        indices_idx1_in_idx2 = idx_1[indices_idx1_in_idx2]\n",
    "                        # indices_idx1_in_idx2  = indices_idx1_in_idx2[ending_index:]\n",
    "                        # starting_index=ending_index\n",
    "                        # ending_index = starting_index\n",
    "                        starting_index = 0\n",
    "                        ending_index = 0\n",
    "                        for elem_index in range(len(indices_idx1_in_idx2)-1):\n",
    "                            #print(\"ayo: \", abs((indices_idx1_in_idx2[elem_index]) - (indices_idx1_in_idx2[elem_index+1])))\n",
    "                            if abs((indices_idx1_in_idx2[elem_index]) - (indices_idx1_in_idx2[elem_index+1])) < 25 :\n",
    "                                ending_index = ending_index+1\n",
    "                            else:\n",
    "                                break\n",
    "                        indices_idx1_in_idx2 = indices_idx1_in_idx2[starting_index:ending_index]\n",
    "                        if(len(indices_idx1_in_idx2) != 0 ):\n",
    "                            mask_discontinuties_energydiff = np.isin(indices_idx1_in_idx2, closest_indices)\n",
    "                            indices_discontinuties_in_energydiff = np.where(mask_discontinuties_energydiff)[0]\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "                            #print(indices_discontinuties_in_energydiff)\n",
    "                            if len(indices_discontinuties_in_energydiff) != 0 :\n",
    "                                for k in range(len(indices_discontinuties_in_energydiff) - 1):\n",
    "                                    idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[k]]+ previous_intersection\n",
    "                                    #print(idx)\n",
    "                                    array1_copy = np.array(array1, copy=True)\n",
    "                                    array1 = np.concatenate([array1[:idx],  array2[idx:idx+1], array1[idx+1:]])\n",
    "                                    array2 = np.concatenate([array2[:idx] , array1_copy[idx:idx+1], array2[idx+1:]])\n",
    "                                    E_array[:,i] = array1\n",
    "                                    E_array[:,j] = array2\n",
    "                                idx = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                #print(idx)\n",
    "                                array1_copy = np.array(array1, copy=True)\n",
    "                                array1 = np.concatenate([array1[:idx],  array2[idx:]])\n",
    "                                array2 =np.concatenate([array2[:idx] , array1_copy[idx:]])\n",
    "                                #print(indices_idx1_in_idx2)\n",
    "                                fitting_distance=25\n",
    "\n",
    "                                if True : #abs(indices_idx1_in_idx2[-1] - indices_idx1_in_idx2[0]) < fitting_distance:\n",
    "                                    array1 = array1.tolist()\n",
    "                                    array2 = array2.tolist()\n",
    "                                    r_data_list = r_data.tolist()\n",
    "                                    #fitting region\n",
    "                                    end_discontinuity = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[-1]]+ previous_intersection\n",
    "                                    start_discontinuity = indices_idx1_in_idx2[indices_discontinuties_in_energydiff[0]]+ previous_intersection\n",
    "                                    fit_E_data_end = min(end_discontinuity+fitting_distance, len(array1))\n",
    "                                    fit_E_data_start= max(start_discontinuity-fitting_distance, 0)\n",
    "                                    # print(fit_E_data_start)\n",
    "                                    # print(fit_E_data_end)\n",
    "                                    fitting_E_data = array1[fit_E_data_start: start_discontinuity] + array1[end_discontinuity: fit_E_data_end]\n",
    "                                    fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "                                    with warnings.catch_warnings():\n",
    "                                        warnings.simplefilter(\"ignore\")\n",
    "                                        poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "                                    r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "                                    polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "                                    array1 = array1[:fit_E_data_start] + polyvals.tolist() + array1[fit_E_data_end:]\n",
    "                                    fitting_E_data = array2[fit_E_data_start: start_discontinuity] + array2[end_discontinuity: fit_E_data_end]\n",
    "                                    fitting_r_data = r_data_list[fit_E_data_start: start_discontinuity] + r_data_list[end_discontinuity:fit_E_data_end]\n",
    "                                    with warnings.catch_warnings():\n",
    "                                        warnings.simplefilter(\"ignore\")\n",
    "                                        poly = np.poly1d(np.polyfit(fitting_r_data, fitting_E_data, 12))\n",
    "                                    r_data_fitting_list =  r_data_list[fit_E_data_start:fit_E_data_end]\n",
    "                                    polyvals = np.polyval(np.asarray(poly),r_data_fitting_list )\n",
    "                                    array2 = array2[:fit_E_data_start] + polyvals.tolist() + array2[fit_E_data_end:]\n",
    "                                E_array[:,i] = array1\n",
    "                                E_array[:,j] = array2\n",
    "                                previous_intersection = idx\n",
    "                except():\n",
    "                    print(\"uh oh\")\n",
    "        new_E_array[:,i ] = E_array[:,i]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return E_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3fe90cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 60 is out of bounds for axis 3 with size 60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cavity_E_array_0_00 \u001b[38;5;241m=\u001b[39m \u001b[43mdeclutter_E_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcavity_E_array_0_00_T\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdipoles_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_to_declutter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cavity_E_array_0_001  \u001b[38;5;241m=\u001b[39m declutter_E_array(cavity_E_array_0_001_T , dipoles_001, r_data, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m1\u001b[39m, num_to_declutter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m cavity_E_array_0_005 \u001b[38;5;241m=\u001b[39m declutter_E_array(cavity_E_array_0_005_T , dipoles_005, r_data, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m1\u001b[39m, num_to_declutter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[46], line 28\u001b[0m, in \u001b[0;36mdeclutter_E_array\u001b[0;34m(E_array, dipoles, r_data, discontinuity_threshold_std, energy_diff_threshold_std_p1, E_disc_threshold, energy_diff_threshold_std, num_to_declutter)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d_matrix\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, r_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] ):\n\u001b[0;32m---> 28\u001b[0m     d_matrices[:, : , i] \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dipole_mag_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdipoles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_to_declutter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m diff_d_matrices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiff(np\u001b[38;5;241m.\u001b[39mdiff(d_matrices))\n\u001b[1;32m     31\u001b[0m diff_d_matrices[diff_d_matrices \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m, in \u001b[0;36mdeclutter_E_array.<locals>.build_dipole_mag_matrix\u001b[0;34m(dipoles, n_elec, r_)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_elec):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_elec):\n\u001b[0;32m---> 18\u001b[0m         d_matrix[i][j] \u001b[38;5;241m=\u001b[39m vector_magnitude(\u001b[43mdipoles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr_\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#d_matrix = d_matrix + d_matrix.T - np.diag(np.diag(d_matrix))\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d_matrix\n",
      "\u001b[0;31mIndexError\u001b[0m: index 60 is out of bounds for axis 3 with size 60"
     ]
    }
   ],
   "source": [
    "cavity_E_array_0_00 = declutter_E_array(cavity_E_array_0_00_T , dipoles_0, r_data, 7, 1, 7, 1, num_to_declutter=10)\n",
    "cavity_E_array_0_001  = declutter_E_array(cavity_E_array_0_001_T , dipoles_001, r_data, 7, 1,7, 1, num_to_declutter=10)\n",
    "cavity_E_array_0_005 = declutter_E_array(cavity_E_array_0_005_T , dipoles_005, r_data, 7, 1, 7, 1, num_to_declutter=10)\n",
    "cavity_E_array_0_05  = declutter_E_array(cavity_E_array_0_05_T , dipoles_01,r_data, 7, 1, 7, 1, num_to_declutter=10)\n",
    "cavity_E_array_0_04  = declutter_E_array(cavity_E_array_0_04_T , dipoles_02, r_data, 7, 1, 7, 1, num_to_declutter=10)\n",
    "cavity_E_array_0_03  = declutter_E_array(cavity_E_array_0_03_T , dipoles_03, r_data, 7, 1, 7, 1, num_to_declutter=10)\n",
    "cavity_E_array_0_02  = declutter_E_array(cavity_E_array_0_02_T , dipoles_04, r_data, 7, 1, 7, 1, num_to_declutter=10)\n",
    "cavity_E_array_0_01  = declutter_E_array(cavity_E_array_0_01_T , dipoles_05, r_data, 7, 1, 7, 1, num_to_declutter=10)\n",
    "\n",
    "LP_arrays = np.array([cavity_E_array_0_00[:,3], \n",
    "            cavity_E_array_0_001[:,3],\n",
    "            cavity_E_array_0_005[:,3],\n",
    "            cavity_E_array_0_01[:,3],\n",
    "            cavity_E_array_0_02[:,3],\n",
    "            cavity_E_array_0_03[:,3],\n",
    "            cavity_E_array_0_04[:,3],\n",
    "            cavity_E_array_0_05[:,3]]\n",
    "             )\n",
    "\n",
    "UP_arrays = np.array([cavity_E_array_0_00[:,5], \n",
    "            cavity_E_array_0_001[:,5],\n",
    "            cavity_E_array_0_005[:,5],\n",
    "            cavity_E_array_0_01[:,5],\n",
    "            cavity_E_array_0_02[:,5],\n",
    "            cavity_E_array_0_03[:,5],\n",
    "            cavity_E_array_0_04[:,5],\n",
    "            cavity_E_array_0_05[:,5]]\n",
    "              )\n",
    "\n",
    "S0_array = cavity_E_array_0_00[:,0]\n",
    "S1_array = cavity_E_array_0_00[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ab6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(r_data, cavity_E_array_0_05[:,5])\n",
    "plt.plot(r_data, cavity_E_array_0_00[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_LP_array = np.zeros((1,8))\n",
    "min_UP_array = np.zeros((1,8))\n",
    "\n",
    "#for i in range(8):\n",
    " #   min_LP_array[0,i] = np.argmin(LP_arrays[i])\n",
    "  #  min_UP_array[0,i] = np.argmin(UP_arrays[i])\n",
    "\n",
    "min_S0_loc = np.argmin(S0_array)\n",
    "min_S1_loc = np.argmin(S1_array)\n",
    "\n",
    "r_eq_ang = r_data[min_S0_loc]\n",
    "print(f'Min on S0 is {r_data[min_S0_loc]}')\n",
    "print(f'Min on S1 is {r_data[min_S1_loc]}')\n",
    "#print(f'Min on LP is {r_data[min_LP_loc]}')\n",
    "#print(f'Min on UP is {r_data[min_UP_loc]}')\n",
    "\n",
    "# Fitting S0 PES to a quintic polynomial\n",
    "au_to_SI = (4.35974 * 10 ** (-18)) * 10 ** 20\n",
    "poly = np.poly1d(np.polyfit(r_data, S0_array, 8))\n",
    "print(poly)\n",
    "\n",
    "#Taking first and second derivative of S0 PES and evaluating at r_eq\n",
    "first_derivative = poly.deriv()\n",
    "second_derivative = first_derivative.deriv()\n",
    "k_test_au = second_derivative(r_eq_ang)\n",
    "k_test_SI = k_test_au * au_to_SI\n",
    "print(k_test_SI)\n",
    "\n",
    "#plotting S0 PES and quintic fit\n",
    "plt.plot(r_data, poly(r_data), 'm-', label='fit')\n",
    "plt.plot(r_data, S0_array, 'bo', label='cavity free |g>')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c595ad2",
   "metadata": {},
   "source": [
    "## Calculation of $ \\text{x}_0 $\n",
    "\n",
    "$$ \\frac{\\hbar}{2}\\sqrt{\\frac{k}{\\mu}} = \\frac{k}{2}(x_0 - x_{eq})^2 + V_0 $$\n",
    "\n",
    "Expanded, solved for $ x_o $, and found zeros using quadratic formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e921ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_amu = 1.00784 * 1.00784 / (1.00784 + 1.00784)\n",
    "mu_kg = mu_amu  * 10 ** (-3) / (6.022 * 10 ** 23) \n",
    "r_eq_SI = r_eq_ang * 10 ** (-10)\n",
    "h_bar = constants.hbar\n",
    "V_0_loc = np.argmin(S0_array)\n",
    "V_0 = S0_array[V_0_loc] * 4.35974 * 10 ** (-18)\n",
    "left = (h_bar / 2) * np.sqrt(k_test_SI / mu_kg)\n",
    "a = 0.5 * k_test_SI \n",
    "b = -k_test_SI * r_eq_SI\n",
    "c = 0.5 * k_test_SI * (r_eq_SI ** 2) - left\n",
    "zeros_n = (-b - np.sqrt((b ** 2) - 4 * a * c)) / (2 * a)\n",
    "zeros_p = (-b + np.sqrt((b ** 2) - 4 * a * c)) / (2 * a)\n",
    "x0_angstrom = zeros_n * 10 ** 10\n",
    "x0_au = x0_angstrom / psi4.constants.bohr2angstroms\n",
    "print(x0_angstrom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378388b2",
   "metadata": {},
   "source": [
    "## Calculation of the Huang-Rhys Factor\n",
    "Huang Rhys factor can be calculated by both\n",
    "\n",
    "$$ S = 1/2(\\Delta x / x_0)^2 \\tag{Turner}$$\n",
    "\n",
    "from the mode anharmonicity paper\n",
    "\n",
    "and \n",
    "\n",
    "$$ S = \\frac{m\\omega_{vib} \\Delta x^2}{2 \\hbar} \\tag{Hsu}$$\n",
    "\n",
    "from the polaritonic Huang-Rhys factor paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247fbde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Constants and Variables\n",
    "delta_au = (r_data[min_S1_loc] - r_data[min_S0_loc]) / psi4.constants.bohr2angstroms\n",
    "\n",
    "delta_LP_au = np.zeros((1,8))\n",
    "delta_UP_au = np.zeros((1,8))\n",
    "\n",
    "for i in range(8):\n",
    "    delta_LP_au[0,i] = (r_data[int(min_LP_array[0,i])] - r_data[min_S0_loc]) / psi4.constants.bohr2angstroms\n",
    "    delta_UP_au[0,i] = (r_data[int(min_UP_array[0,i])] - r_data[min_S0_loc]) / psi4.constants.bohr2angstroms\n",
    "\n",
    "\n",
    "delta_m = (r_data[min_S1_loc] - r_data[min_S0_loc]) * 10 ** (-10)\n",
    "delta_angstrom = (r_data[min_S1_loc] - r_data[min_S0_loc])\n",
    "omega_vib = np.sqrt(k_test_SI / mu_kg)\n",
    "h_bar = constants.hbar\n",
    "x0_test = np.sqrt(h_bar * omega_vib / k_test_SI)\n",
    "x0_test_au = (x0_test * 10 ** (10))  / psi4.constants.bohr2angstroms\n",
    "\n",
    "# Turner\n",
    "S_Turner = 0.5 * (delta_au / x0_test_au) ** 2\n",
    "\n",
    "# Hsu\n",
    "S_Hsu = mu_kg * omega_vib * delta_m ** 2 / (2 * h_bar)\n",
    "\n",
    "#g and LP \n",
    "\n",
    "HR_LP_array = np.zeros((1,8))\n",
    "HR_UP_array = np.zeros((1,8))\n",
    "\n",
    "for i in range(8):\n",
    "    HR_LP_array[0,i] = 0.5 * (delta_LP_au[0,i] / x0_test_au) ** 2\n",
    "    HR_UP_array[0,i] = 0.5 * (delta_UP_au[0,i] / x0_test_au) ** 2\n",
    "\n",
    "print('|g> and |e> HR Factor')\n",
    "print(S_Turner)\n",
    "print(S_Hsu)\n",
    "\n",
    "print('LP and UP HR Factor')\n",
    "print(HR_LP_array)\n",
    "print(HR_UP_array)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(HR_UP_array.reshape(-1,1))\n",
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66994e19-bf39-4e81-9e46-b6ad75c797f9",
   "metadata": {},
   "source": [
    "First plot the ground-state potential energy surfaces for $ \\text{H2} $ inside and outisde the cavity.  The effect of the cavity will raise the energy slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ca631-25f0-4ed9-8701-682e1e336cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_list = [0, 0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "fci_S0_omega = np.zeros((1, N_R))\n",
    "for i in range(N_R):\n",
    "    fci_S0_omega[0,i] = S0_array[i] + 0.1941582620721647\n",
    "fci_S0_plusw = np.ndarray.flatten(fci_S0_omega)\n",
    "\n",
    "color_list_1 = ['grey','violet','indigo','blue','green','yellow','orange','red']\n",
    "\n",
    "plt.plot(r_data, fci_S0_plusw, linestyle='dashed', color='gray', label=f'$\\lambda$ = 0')\n",
    "plt.plot(r_data, S1_array, linestyle='--', color='gray')\n",
    "\n",
    "# for i in range(2,8):\n",
    "#     plt.plot(r_data, LP_arrays[i,:], f'{color_list_1[i]}', label=f'$\\lambda$ = {lambda_list[i]}')\n",
    "# for k in range(2,8):\n",
    "#         plt.plot(r_data, UP_arrays[k,:], f'{color_list_1[k]}',)\n",
    "\n",
    "plt.xlabel('r (Angstrom)')\n",
    "plt.ylabel('E (Hartree)')\n",
    "\n",
    "\n",
    "#plt.xlim(1.5, 2)\n",
    "#plt.ylim(-7.76, -7.72)\n",
    "plt.legend(loc = 'upper right', ncols = 3, fontsize = 'small')\n",
    "plt.savefig('polariton_surfaces_HF.png',dpi=500)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(matrix).to_clipboard()\n",
    "\n",
    "omega_test = np.abs(cavity_E_array_0_00[60,4] - S0_array[60])\n",
    "print(omega_test)\n",
    "print(r_data[60])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d601c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2847671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
